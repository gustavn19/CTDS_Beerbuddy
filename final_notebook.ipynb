{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Beer Recommender System\n",
    "This notebook implements data preprocessing and modeling techniques to create a beer recommender system. I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gustavnielsen/Documents/Comp_tools_project/env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from collections import defaultdict\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing Functions\n",
    "These functions clean the dataset by handling duplicates, missing values, and incorrect formats. They prepare the data for splitting and analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(df):\n",
    "    df_filtered = df.drop_duplicates([\"name\", \"reviewer\", \"review_text\"]) # Remove duplicate entries\n",
    "    print(\"Size after drop_duplicates: \", len(df_filtered))\n",
    "    \n",
    "    df_filtered['rating'] = pd.to_numeric(df_filtered['rating'], errors='coerce')  # Set erros to NaN\n",
    "    df_filtered = df_filtered.dropna(subset=['rating'])  # Drop rows where 'rating' is NaN\n",
    "    print(\"Size after drop rating NA: \", len(df_filtered))\n",
    "    \n",
    "    df_filtered['abv'] = pd.to_numeric(df_filtered['abv'].str.rstrip('%'), errors='coerce') \n",
    "    df_filtered = df_filtered.dropna(subset=['abv'])\n",
    "    print(\"Size after drop abv NA: \", len(df_filtered))\n",
    "    \n",
    "    return df_filtered\n",
    "\n",
    "def create_test_train(df, reviewer_col=\"reviewer\", random_state=7, test_size=100, mask_percentage=0.10):\n",
    "    \"\"\"\n",
    "    Splits a dataset into training and test sets, masking a portion of test set entries.\n",
    "    \n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): The dataset to split.\n",
    "    - reviewer_col (str): The column name containing reviewer IDs.\n",
    "    - random_state (int): The random state for reproducibility.\n",
    "    - test_size (int): The number of reviewers to sample for the test set.\n",
    "    - mask_percentage (float): The percentage of beers to mask for each reviewer in the test set.\n",
    "\n",
    "    Returns:\n",
    "    - df_train (pd.DataFrame): The training set.\n",
    "    - df_test_masked (pd.DataFrame): The test set with masked entries.\n",
    "    \"\"\"\n",
    "    # Randomly sample reviewers\n",
    "    sampled_reviewers = df[reviewer_col].sample(n=test_size, random_state=random_state)\n",
    "    \n",
    "    # Get reviews from the sampled reviewers\n",
    "    df_test = df[df[reviewer_col].isin(sampled_reviewers)]\n",
    "    \n",
    "    # Group by reviewer to get each user's beers\n",
    "    df_test_grouped = df_test.groupby(reviewer_col)\n",
    "    \n",
    "    # Randomly mask a percentage of beers for each reviewer\n",
    "    test_set_masked = []\n",
    "    for reviewer, group in df_test_grouped:\n",
    "        # Calculate how many beers to mask\n",
    "        num_to_mask = max(int(len(group) * mask_percentage), 1)\n",
    "        \n",
    "        # Sample the calculated number of beers\n",
    "        masked_group = group.sample(n=num_to_mask, random_state=random_state)\n",
    "        test_set_masked.append(masked_group)\n",
    "    \n",
    "    # Combine masked reviews into a single DataFrame\n",
    "    df_test_masked = pd.concat(test_set_masked)\n",
    "    \n",
    "    # Remove masked reviews from the training data\n",
    "    df_train = df.drop(df_test_masked.index)\n",
    "    \n",
    "    # Display dataset summaries\n",
    "    print(\"\\n### Dataset Summary ###\")\n",
    "    print(f\"Total reviewers sampled: {len(sampled_reviewers)}\")\n",
    "    print(f\"Training set size: {df_train.shape}\")\n",
    "    print(f\"Test set size: {df_test_masked.shape}\")\n",
    "    \n",
    "    return df_train, df_test_masked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size after drop_duplicates:  1157819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ql/h53w_qjs60509nsf4jbr01c00000gn/T/ipykernel_38694/3114772741.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtered['rating'] = pd.to_numeric(df_filtered['rating'], errors='coerce')  # Set erros to NaN\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size after drop rating NA:  1157807\n",
      "Size after drop abv NA:  1154739\n"
     ]
    }
   ],
   "source": [
    "# Load data and preprocess\n",
    "df = pd.read_pickle('encoded_beers_SBERT.pkl')\n",
    "\n",
    "df_filtered = preprocess_data(df)\n",
    "del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>brewery</th>\n",
       "      <th>subgenre</th>\n",
       "      <th>abv</th>\n",
       "      <th>location</th>\n",
       "      <th>rating</th>\n",
       "      <th>average_rating</th>\n",
       "      <th>reviewer</th>\n",
       "      <th>review_date</th>\n",
       "      <th>review_text</th>\n",
       "      <th>algorithm_rating</th>\n",
       "      <th>total_reviews</th>\n",
       "      <th>sbert_embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Wild Dog Pale Ale</td>\n",
       "      <td>Wild Dog (Tiemann Beer)</td>\n",
       "      <td>American Pale Ale</td>\n",
       "      <td>5.2</td>\n",
       "      <td>ðŸ‡¯ðŸ‡ªJersey</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.99</td>\n",
       "      <td>Jerseyislandbeer</td>\n",
       "      <td>December 14, 2023</td>\n",
       "      <td>330ml can from Shoprite in Livingstone. At hom...</td>\n",
       "      <td>28.0</td>\n",
       "      <td>11</td>\n",
       "      <td>[0.037878353, 0.00593541, 0.0062317043, -0.011...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Wild Dog Pale Ale</td>\n",
       "      <td>Wild Dog (Tiemann Beer)</td>\n",
       "      <td>American Pale Ale</td>\n",
       "      <td>5.2</td>\n",
       "      <td>ðŸ‡¬ðŸ‡§Ipswich, England</td>\n",
       "      <td>3.2</td>\n",
       "      <td>2.99</td>\n",
       "      <td>Grumbo</td>\n",
       "      <td>February 28, 2022</td>\n",
       "      <td>18/2/2022. Can sample courtesy of fonefan, che...</td>\n",
       "      <td>28.0</td>\n",
       "      <td>11</td>\n",
       "      <td>[-0.037820198, -0.044825517, 0.07764052, 0.065...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Wild Dog Pale Ale</td>\n",
       "      <td>Wild Dog (Tiemann Beer)</td>\n",
       "      <td>American Pale Ale</td>\n",
       "      <td>5.2</td>\n",
       "      <td>ðŸ‡¸ðŸ‡ªTyresÃ¶, Sweden</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.99</td>\n",
       "      <td>omhper</td>\n",
       "      <td>February 19, 2022</td>\n",
       "      <td>--Sample, thanks fonefan! -- Hazy deep golden,...</td>\n",
       "      <td>28.0</td>\n",
       "      <td>11</td>\n",
       "      <td>[0.056960188, -0.00059301173, 0.11057871, 0.02...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Wild Dog Pale Ale</td>\n",
       "      <td>Wild Dog (Tiemann Beer)</td>\n",
       "      <td>American Pale Ale</td>\n",
       "      <td>5.2</td>\n",
       "      <td>ðŸ‡«ðŸ‡®Vasa, Finland</td>\n",
       "      <td>2.8</td>\n",
       "      <td>2.99</td>\n",
       "      <td>oh6gdx</td>\n",
       "      <td>January 31, 2022</td>\n",
       "      <td>Panda from a can, thanks fonefan!. Golden colo...</td>\n",
       "      <td>28.0</td>\n",
       "      <td>11</td>\n",
       "      <td>[0.003549767, -0.010705345, 0.02083684, 0.0106...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>Wild Dog Pale Ale</td>\n",
       "      <td>Wild Dog (Tiemann Beer)</td>\n",
       "      <td>American Pale Ale</td>\n",
       "      <td>5.2</td>\n",
       "      <td>ðŸ‡©ðŸ‡°Haderslev, Denmark</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.99</td>\n",
       "      <td>martin00sr</td>\n",
       "      <td>January 8, 2022</td>\n",
       "      <td>Can @Ulfborg. Cloudy amber, white head. Malty ...</td>\n",
       "      <td>28.0</td>\n",
       "      <td>11</td>\n",
       "      <td>[-0.01005388, -0.02942978, 0.0016338513, 0.017...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id               name                  brewery           subgenre  abv  \\\n",
       "0   1  Wild Dog Pale Ale  Wild Dog (Tiemann Beer)  American Pale Ale  5.2   \n",
       "1   2  Wild Dog Pale Ale  Wild Dog (Tiemann Beer)  American Pale Ale  5.2   \n",
       "2   3  Wild Dog Pale Ale  Wild Dog (Tiemann Beer)  American Pale Ale  5.2   \n",
       "3   4  Wild Dog Pale Ale  Wild Dog (Tiemann Beer)  American Pale Ale  5.2   \n",
       "4   6  Wild Dog Pale Ale  Wild Dog (Tiemann Beer)  American Pale Ale  5.2   \n",
       "\n",
       "               location  rating  average_rating          reviewer  \\\n",
       "0              ðŸ‡¯ðŸ‡ªJersey     3.5            2.99  Jerseyislandbeer   \n",
       "1    ðŸ‡¬ðŸ‡§Ipswich, England     3.2            2.99            Grumbo   \n",
       "2      ðŸ‡¸ðŸ‡ªTyresÃ¶, Sweden     3.5            2.99            omhper   \n",
       "3       ðŸ‡«ðŸ‡®Vasa, Finland     2.8            2.99            oh6gdx   \n",
       "4  ðŸ‡©ðŸ‡°Haderslev, Denmark     2.6            2.99        martin00sr   \n",
       "\n",
       "         review_date                                        review_text  \\\n",
       "0  December 14, 2023  330ml can from Shoprite in Livingstone. At hom...   \n",
       "1  February 28, 2022  18/2/2022. Can sample courtesy of fonefan, che...   \n",
       "2  February 19, 2022  --Sample, thanks fonefan! -- Hazy deep golden,...   \n",
       "3   January 31, 2022  Panda from a can, thanks fonefan!. Golden colo...   \n",
       "4    January 8, 2022  Can @Ulfborg. Cloudy amber, white head. Malty ...   \n",
       "\n",
       "  algorithm_rating  total_reviews  \\\n",
       "0             28.0             11   \n",
       "1             28.0             11   \n",
       "2             28.0             11   \n",
       "3             28.0             11   \n",
       "4             28.0             11   \n",
       "\n",
       "                                     sbert_embedding  \n",
       "0  [0.037878353, 0.00593541, 0.0062317043, -0.011...  \n",
       "1  [-0.037820198, -0.044825517, 0.07764052, 0.065...  \n",
       "2  [0.056960188, -0.00059301173, 0.11057871, 0.02...  \n",
       "3  [0.003549767, -0.010705345, 0.02083684, 0.0106...  \n",
       "4  [-0.01005388, -0.02942978, 0.0016338513, 0.017...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filtered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### Dataset Summary ###\n",
      "Total reviewers sampled: 100\n",
      "Training set size: (1149910, 14)\n",
      "Test set size: (4829, 14)\n"
     ]
    }
   ],
   "source": [
    "df_train, df_test_masked = create_test_train(df_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe for retrieving beer information\n",
    "beer_info = df_filtered[['name', 'abv', 'subgenre']]\n",
    "\n",
    "# Drop duplicate rows based on the 'name' column (i.e. beers)\n",
    "beer_info = beer_info.drop_duplicates(subset='name')\n",
    "\n",
    "beer_info.set_index('name', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create locality-sensitive hashing (LSH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a variable to store the model\n",
    "sbert_model = None\n",
    "\n",
    "def encode_sbert(query, model_name='sentence-transformers/all-MiniLM-L6-v2'):\n",
    "    \"\"\"\n",
    "    Encodes a query using SBERT. Loads the model if not already loaded.\n",
    "    \n",
    "    Parameters:\n",
    "        query (str or list of str): The query or list of queries to encode.\n",
    "        model_name (str): The name of the SBERT model to load (default is 'all-MiniLM-L6-v2').\n",
    "    \n",
    "    Returns:\n",
    "        numpy.ndarray: The embedding(s) for the input query/queries.\n",
    "    \"\"\"\n",
    "    global sbert_model  # Use the global variable to store the model\n",
    "    \n",
    "    # Load the model if it's not already loaded\n",
    "    if sbert_model is None:\n",
    "        sbert_model = SentenceTransformer(model_name)\n",
    "    \n",
    "    # Encode the query and return the embeddings\n",
    "    return sbert_model.encode(query)\n",
    "\n",
    "def generate_hyperplanes(dim, num_hash_functions):\n",
    "    \"\"\"\n",
    "    Generate random hyperplanes for hash functions.\n",
    "    \n",
    "    Parameters:\n",
    "    - dim: Dimensionality of the embeddings.\n",
    "    - num_hash_functions: Number of hash functions per table.\n",
    "    \n",
    "    Returns:\n",
    "    - A matrix of shape (num_hash_functions, dim) where each row is a hyperplane.\n",
    "    \"\"\"\n",
    "    return np.random.randn(num_hash_functions, dim)\n",
    "\n",
    "def hash_vectors(vectors, hyperplanes):\n",
    "    \"\"\"\n",
    "    Hash a batch of vectors using a set of hyperplanes.\n",
    "\n",
    "    Parameters:\n",
    "    - vectors: Input vectors (2D array of shape [n_samples, d]).\n",
    "    - hyperplanes: Matrix of hyperplanes (2D array of shape [k, d]).\n",
    "\n",
    "    Returns:\n",
    "    - A matrix of binary hash values (shape [n_samples, k]).\n",
    "    \"\"\"\n",
    "    # Compute dot products and return binary hash values\n",
    "    return (np.dot(vectors, hyperplanes.T) > 0).astype(int)\n",
    "\n",
    "class LSHVectorized:\n",
    "    def __init__(self, d, k, L):\n",
    "        \"\"\"\n",
    "        Initialize the LSH scheme with vectorized support.\n",
    "\n",
    "        Parameters:\n",
    "        - d: Dimensionality of the input vectors.\n",
    "        - k: Number of hash functions per table.\n",
    "        - L: Number of hash tables.\n",
    "        \"\"\"\n",
    "        self.L = L\n",
    "        self.tables = [defaultdict(list) for _ in range(L)]\n",
    "        self.hyperplanes = [generate_hyperplanes(d, k) for _ in range(L)]\n",
    "\n",
    "    def add_vectors(self, vectors, identifiers):\n",
    "        \"\"\"\n",
    "        Add a batch of vectors to the LSH index.\n",
    "\n",
    "        Parameters:\n",
    "        - vectors: Input vectors (2D array of shape [n_samples, d]).\n",
    "        - identifiers: A list of unique identifiers for the vectors.\n",
    "        \"\"\"\n",
    "        for table, hyperplanes in zip(self.tables, self.hyperplanes):\n",
    "            # Compute hash values for all vectors at once\n",
    "            hash_values = hash_vectors(vectors, hyperplanes)\n",
    "            \n",
    "            # Convert binary hash values to tuples for dictionary keys\n",
    "            hash_keys = [tuple(h) for h in hash_values]\n",
    "            \n",
    "            # Add vectors to their corresponding buckets\n",
    "            for identifier, key in zip(identifiers, hash_keys):\n",
    "                table[key].append(identifier)\n",
    "\n",
    "    def query(self, vectors):\n",
    "        \"\"\"\n",
    "        Query the LSH index to find similar items for a batch of vectors.\n",
    "\n",
    "        Parameters:\n",
    "        - vectors: Query vectors (2D array of shape [n_samples, d]).\n",
    "\n",
    "        Returns:\n",
    "        - A list of sets, where each set contains the candidates for a query vector.\n",
    "        \"\"\"\n",
    "        candidates = [set() for _ in range(len(vectors))]\n",
    "        for table, hyperplanes in zip(self.tables, self.hyperplanes):\n",
    "            # Compute hash values for all query vectors\n",
    "            hash_values = hash_vectors(vectors, hyperplanes)\n",
    "            \n",
    "            # Convert binary hash values to tuples for dictionary keys\n",
    "            hash_keys = [tuple(h) for h in hash_values]\n",
    "            \n",
    "            # Retrieve candidates for each query\n",
    "            for i, key in enumerate(hash_keys):\n",
    "                candidates[i].update(table.get(key, []))\n",
    "        return candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = np.vstack(df_train[\"sbert_embedding\"].values)  # Combine embeddings into a 2D array\n",
    "identifiers = df_train.index.tolist()  # Use review IDs as identifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Run LSH ##\n",
    "# Initialize LSH scheme\n",
    "d = 384\n",
    "k = 14 \n",
    "L = 7\n",
    "\n",
    "lsh = LSHVectorized(d, k, L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add vectors to the LSH index\n",
    "lsh.add_vectors(vectors, identifiers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Collaborative Filtering (CF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def predict_ratings_user_based(user_item_matrix, similarity_matrix):\n",
    "   \n",
    "    \"\"\"\n",
    "    this function predicts the ratings for the user_item_matrix using the similarity_matrix\n",
    "    \n",
    "\n",
    "    Parameters: \n",
    "    \n",
    "    - user_item_matrix (DataFrame): User-item matrix with ratings centered around the user mean.\n",
    "    - similarity_matrix (DataFrame): User-user similarity matrix.\n",
    "    \n",
    "    Returns:\n",
    "        - pred (DataFrame): Predicted ratings for all user-item pairs.\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    # Compute predictions\n",
    "    similarity_sum = np.abs(similarity_matrix).sum(axis=1)[:, None]\n",
    "    pred = np.dot(similarity_matrix, user_item_matrix) / (similarity_sum + 1e-8)\n",
    "\n",
    "\n",
    "\n",
    "    return pred\n",
    "\n",
    "\n",
    "def collaborative_filtering(df):\n",
    "    \n",
    "    \"\"\"\n",
    "    Predicts user ratings for items using user-based collaborative filtering with cosine similarity. \n",
    "    Preprocesses the input data to create a centered user-item matrix, computes user similarities, \n",
    "    and generates predicted ratings.\n",
    "\n",
    "    Parameters:\n",
    "    - df (DataFrame): Input data with 'reviewer', 'name', and 'rating' columns.\n",
    "\n",
    "    Returns:\n",
    "    - pr_df (DataFrame): Predicted ratings for all user-item pairs.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    user_item_matrix = df.pivot_table(\n",
    "    index=\"reviewer\",     # Rows: Reviewers\n",
    "    columns=\"name\",       # Columns: Beer names\n",
    "    values=\"rating\",      # Values: Ratings\n",
    "    fill_value=0          # Fill missing ratings with 0\n",
    "    )\n",
    "    \n",
    "\n",
    "    #user_means = user_item_matrix.replace(0, np.nan).mean(axis=1).fillna(0).to_numpy()\n",
    "    #print(user_means)\n",
    "    #user_item_np = np.where(user_item_matrix != 0, user_item_matrix - user_means[:, None], 0)\n",
    "    user_item_np = np.where(user_item_matrix != 0, (user_item_matrix - 3) / 2, 0)\n",
    "    user_item_matrix = pd.DataFrame(user_item_np, index=user_item_matrix.index, columns=user_item_matrix.columns)\n",
    "\n",
    "\n",
    "    # Compute cosine similarity\n",
    "    cosine_similarity_matrix = cosine_similarity(user_item_matrix)\n",
    "    \n",
    "    # Predict ratings\n",
    "    predicted_ratings = predict_ratings_user_based(user_item_matrix, cosine_similarity_matrix)\n",
    "\n",
    "    df_out = pd.DataFrame(predicted_ratings, index=user_item_matrix.index, columns=user_item_matrix.columns)\n",
    "   \n",
    "    return df_out\n",
    "\n",
    "\n",
    "collab_df = collaborative_filtering(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    33531.000000\n",
       "mean         4.749085\n",
       "std         13.940269\n",
       "min          0.034176\n",
       "25%          0.128161\n",
       "50%          0.375940\n",
       "75%          1.768626\n",
       "max        100.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Caculate fraction of beers per user which is zero\n",
    "zero_percentage = (collab_df == 0).mean(axis=1) * 100\n",
    "zero_percentage.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review Term Explanations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.preprocessing import StandardScaler, normalize\n",
    "from sklearn.decomposition import PCA\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Define reference context for flavor-related words. The first 20 is from a aromatic kit used for sommeliers, the rest is ai-generated.\n",
    "context_words = [\n",
    "    \"bitter\", \"sweet\", \"salt\", \"sour\", \"umami\",\n",
    "    \"lemon\", \"grapefruit\", \"apple\", \"pear\", \"blackcurrant\", \"prune\", \"melon\", \n",
    "    \"banana\", \"acacia\", \"rose\", \"cut grass\", \"hay\", \"bay leaf\", \"thyme\", \n",
    "    \"tomato\", \"pepper\", \"nutmeg\", \"clove\", \"bread\", \"butter\", \"vanilla\", \n",
    "    \"hazelnut\", \"toast\", \"malt\", \"caramel\", \"honey\", \"coffee\", \"licorice\",\n",
    "    \"pine\", \"grass\", \"resin\", \"floral\", \"perfume\", \"incense\", \"cinnamon\",\n",
    "    \"ginger\", \"anise\", \"nut\", \"almond\", \"walnut\", \"chestnut\", \"peanut\",\n",
    "    \"soy\", \"mushroom\", \"earth\", \"dust\", \"wood\", \"barnyard\", \"horse\",\n",
    "    \"wet\", \"dry\", \"metallic\", \"sulfur\", \"fish\", \"cheese\", \"butter\",\n",
    "    \"cream\", \"leather\", \"silk\", \"rubber\", \"barnyard\", \"ammonia\",\n",
    "    \"rotten\", \"acid\"\n",
    "]\n",
    "custom_stop_words = [\"beer\", \"beers\", \"bottle\", \"taste\", \"nice\", \"aroma\", \"like\", \"good\", \"great\", \"head\", \"flavor\", \"flavors\", \"flavour\", \"flavours\", \"brew\", \"can\"]\n",
    "context_embeddings = encode_sbert(context_words)\n",
    "\n",
    "# Function to filter terms dynamically\n",
    "def is_flavor_related(term, context_embeddings, threshold=0.35):\n",
    "    term_embedding = sbert_model.encode([term])[0]\n",
    "    cosine_similarity = lambda x, y: np.dot(x, y) / (np.linalg.norm(x) * np.linalg.norm(y))\n",
    "    max_similarity = max(cosine_similarity(term_embedding, context) for context in context_embeddings)\n",
    "    return max_similarity > threshold\n",
    "\n",
    "def plot_bucket(bucket_vectors, cluster_labels, perplexity=30, n_iter=5000, learning_rate=200):\n",
    "    \"\"\"\n",
    "    Visualizes differences within an LSH bucket using t-SNE with configurable parameters.\n",
    "    \n",
    "    Args:\n",
    "        bucket_vectors (np.ndarray): High-dimensional vectors of beers in the bucket.\n",
    "        cluster_labels (np.ndarray): Cluster labels assigned to each vector.\n",
    "        subgenres (np.ndarray): Subgenre or categorical labels for each beer.\n",
    "        perplexity (int): The t-SNE perplexity parameter, balancing local/global data views.\n",
    "        n_iter (int): Number of iterations for t-SNE optimization.\n",
    "        learning_rate (float): Learning rate for t-SNE optimization.\n",
    "    \"\"\"\n",
    "    # t-SNE reducer with tuned parameters\n",
    "    reducer = TSNE(\n",
    "        n_components=2, \n",
    "        random_state=42, \n",
    "        perplexity=perplexity, \n",
    "        n_iter=n_iter, \n",
    "        learning_rate=learning_rate\n",
    "    )\n",
    "    reduced_vectors = reducer.fit_transform(bucket_vectors)\n",
    "    \n",
    "    # Plotting\n",
    "    plt.figure(figsize=(16, 10))\n",
    "    scatter = plt.scatter(\n",
    "        reduced_vectors[:, 0],\n",
    "        reduced_vectors[:, 1],\n",
    "        c=cluster_labels,\n",
    "        cmap='plasma',\n",
    "        alpha=0.7\n",
    "    )\n",
    "    plt.colorbar(scatter, label='Cluster Label')\n",
    "    plt.title(f\"t-SNE Visualization (Perplexity={perplexity}, n_iter={n_iter}, LR={learning_rate})\")\n",
    "    plt.xlabel(\"Component 1\")\n",
    "    plt.ylabel(\"Component 2\")\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.show()\n",
    "\n",
    "def getThemes(df_filtered, beer_name, query_embedding, limit=100):\n",
    "    # Initialize CountVectorizer with custom stopwords\n",
    "    default_stop_words = CountVectorizer(stop_words='english').get_stop_words()\n",
    "    all_stop_words = list(set(default_stop_words).union(custom_stop_words))\n",
    "\n",
    "    # Pass the combined stop words to CountVectorizer\n",
    "    vectorizer = CountVectorizer(max_features=100, stop_words=all_stop_words, token_pattern=r'\\b[a-zA-Z]{2,}\\b')\n",
    "    df_beer = df_filtered[df_filtered[\"name\"] == beer_name]\n",
    "    # Extract top terms from cluster reviews\n",
    "    term_matrix = vectorizer.fit_transform(df_beer[\"review_text\"])\n",
    "    terms = vectorizer.get_feature_names_out()\n",
    "    term_counts = np.array(term_matrix.sum(axis=0)).flatten()\n",
    "    top_terms = [terms[i] for i in term_counts.argsort()[-limit:]]  # Top 5 terms\n",
    "    filtered_top_terms = [term for term in top_terms if is_flavor_related(term, context_embeddings)]\n",
    "    \n",
    "    # Return the terms most similar to the query\n",
    "    term_embeddings = np.vstack([encode_sbert(term) for term in filtered_top_terms])\n",
    "    \n",
    "    # Calculate cosine similarity between query and terms\n",
    "    similarities = cosine_similarity(query_embedding, term_embeddings)[0]\n",
    "    \n",
    "    # Create a DataFrame to store terms and their similarities\n",
    "    term_similarity_df = pd.DataFrame({\n",
    "        'term': filtered_top_terms,\n",
    "        'similarity': similarities\n",
    "    })\n",
    "    \n",
    "    # Sort terms by similarity to the query\n",
    "    term_similarity_df = term_similarity_df.sort_values(by='similarity', ascending=False)\n",
    "    \n",
    "    # Return the top similar themes\n",
    "    return term_similarity_df['term'].head(10).tolist()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-means clustering of word vectors in buckets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmeans_bucket(bucket_vectors, bucket_data, embedded_query, n_clusters = 15):\n",
    "    # Perform clustering on bucket vectors\n",
    "    kmeans = KMeans(n_clusters=n_clusters, n_init='auto', random_state=7)\n",
    "    cluster_labels = kmeans.fit_predict(bucket_vectors)\n",
    "    \n",
    "    # Assign query to the nearest cluster\n",
    "    query_cluster = kmeans.predict(embedded_query)[0]\n",
    "\n",
    "    # Filter beers in the same cluster as the query\n",
    "    cluster_indices = np.where(cluster_labels == query_cluster)[0]\n",
    "    cluster_vectors = bucket_vectors[cluster_indices]\n",
    "    cluster_beers = bucket_data.iloc[cluster_indices]\n",
    "    \n",
    "    # Compute similarities within the selected cluster\n",
    "    sims = cosine_similarity(embedded_query, cluster_vectors)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make reccomendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_beer_B(query_embedding, df_train, user_name, beer_info, abv_desired=None, style_desired=None, n_clusters=15):\n",
    "    # Query the LSH index\n",
    "    candidates = lsh.query(query_embedding)\n",
    "\n",
    "    # Filter bucket vectors and metadata\n",
    "    bucket_data = df_train[df_train[\"id\"].isin(list(candidates[0]))]\n",
    "    bucket_vectors = np.vstack(bucket_data[\"sbert_embedding\"].to_numpy())\n",
    "    \n",
    "    # Extract subgenre information\n",
    "    subgenres = bucket_data[\"subgenre\"].values  # Adjust column name as necessary\n",
    "\n",
    "    # Perform clustering on bucket vectors\n",
    "    kmeans = KMeans(n_clusters=n_clusters, n_init='auto', random_state=42)\n",
    "    cluster_labels = kmeans.fit_predict(bucket_vectors)\n",
    "    \n",
    "    # Assign query to the nearest cluster\n",
    "    query_cluster = kmeans.predict(query_embedding)[0]\n",
    "\n",
    "    # Filter beers in the same cluster as the query\n",
    "    cluster_indices = np.where(cluster_labels == query_cluster)[0]\n",
    "    cluster_vectors = bucket_vectors[cluster_indices]\n",
    "    cluster_beers = bucket_data.iloc[cluster_indices]\n",
    "    \n",
    "    # Compute similarities within the selected cluster\n",
    "    sims = cosine_similarity(query_embedding, cluster_vectors)[0]\n",
    "\n",
    "    # Perform collaborative filtering\n",
    "    predcicted_rating_user = collab_df.loc[user_name]\n",
    "    \n",
    "    beer_LSH = pd.DataFrame({\n",
    "        'similarity': sims,\n",
    "        'beer': cluster_beers[\"name\"].values,  # Adjust column name if necessary\n",
    "    })\n",
    "    \n",
    "    LSH_score = beer_LSH.groupby('beer')['similarity'].mean()\n",
    "    \n",
    "    collab_filtering_scores = predcicted_rating_user[LSH_score.index.tolist()] # Get CF_score for user for the beers in cluster\n",
    "\n",
    "    if abv_desired:\n",
    "        # Penalise difference in abv by using a nonlinear function penalising greater differences more\n",
    "        abv = beer_info.loc[LSH_score.index.tolist()][\"abv\"]\n",
    "\n",
    "        alpha = 0.05\n",
    "        if abv_desired == 0:\n",
    "            abv_weight = -2 * abs(abv - abv_desired)\n",
    "        else:\n",
    "            abv_weight = -alpha * ((abv - abv_desired)**2) / (abv_desired**1.5 + 1)\n",
    "    else:\n",
    "        abv_weight = 0\n",
    "\n",
    "\n",
    "\n",
    "    beta = 0.6 + 0.004*zero_percentage.loc[user_name] # Linear function to scale beta such that persons with few reviews rely more on LSH and vice versa\n",
    "    \n",
    "    # Add bonus for match in style\n",
    "    style_bonus = np.zeros(len(LSH_score))\n",
    "    if style_desired:\n",
    "        relevant_styles = beer_info.loc[LSH_score.index.tolist()][\"subgenre\"]\n",
    "        style_mask = relevant_styles == style_desired\n",
    "        style_bonus[style_mask] = 0.05\n",
    "    \n",
    "    \n",
    "    # Combine weights and scores\n",
    "    weighted_score = (\n",
    "        beta * LSH_score +\n",
    "        (1-beta) * collab_filtering_scores +\n",
    "        abv_weight +\n",
    "        style_bonus\n",
    "    )\n",
    "\n",
    "    # Create final DataFrame\n",
    "    beer_weighted_score = pd.DataFrame({\n",
    "        'beer': LSH_score.index,\n",
    "        'score': weighted_score,\n",
    "        'abv': abv.values,\n",
    "        'LSH_score': LSH_score.values,\n",
    "        'LSH_score_weighted': LSH_score.values * beta,\n",
    "        'collab_score': collab_filtering_scores.values,\n",
    "        'collab_score_weighted': collab_filtering_scores.values * (1-beta),\n",
    "        'abv_diff': abs(abv.values - abv_desired),\n",
    "        'abv_weight': abv_weight.values,\n",
    "        'Style bonus': style_bonus,\n",
    "        'Weight beta': beta\n",
    "    })\n",
    "    \n",
    "    # Remove index of weighted score and keep the beer name as a column\n",
    "    beer_weighted_score.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    # Get the 10 beers with the highest weighted scores\n",
    "    beer_weighted_score = beer_weighted_score.sort_values(by='score', ascending=False)\n",
    "    beer_weighted_score['notes'] = \"\"\n",
    "    # Apply getThemes to each beer in the DataFrame\n",
    "    #beer_weighted_score['notes'] = beer_weighted_score['beer'].apply(lambda x: getThemes(df_train, x, query_embedding))\n",
    "    #beer_weighted_score.loc[:9, 'notes'] = beer_weighted_score.loc[:9, 'beer'].apply(\n",
    "    #    lambda x: getThemes(df_train, x, query_embedding)) # TODO Fix!\n",
    "\n",
    "    return beer_weighted_score.sort_values(by='score', ascending=False)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 recommended beers:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>beer</th>\n",
       "      <th>score</th>\n",
       "      <th>abv</th>\n",
       "      <th>LSH_score</th>\n",
       "      <th>LSH_score_weighted</th>\n",
       "      <th>collab_score</th>\n",
       "      <th>collab_score_weighted</th>\n",
       "      <th>abv_diff</th>\n",
       "      <th>abv_weight</th>\n",
       "      <th>Style bonus</th>\n",
       "      <th>Weight beta</th>\n",
       "      <th>notes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>639</th>\n",
       "      <td>NÃ¸rrebro Pacific Summer Ale (Ã˜kologisk)</td>\n",
       "      <td>0.460435</td>\n",
       "      <td>5.6</td>\n",
       "      <td>0.777055</td>\n",
       "      <td>0.466313</td>\n",
       "      <td>-0.002144</td>\n",
       "      <td>-0.000857</td>\n",
       "      <td>1.4</td>\n",
       "      <td>-0.005020</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.600103</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424</th>\n",
       "      <td>Insel-Brauerei Insel Saison</td>\n",
       "      <td>0.455709</td>\n",
       "      <td>5.5</td>\n",
       "      <td>0.772663</td>\n",
       "      <td>0.463677</td>\n",
       "      <td>-0.005514</td>\n",
       "      <td>-0.002205</td>\n",
       "      <td>1.5</td>\n",
       "      <td>-0.005763</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.600103</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508</th>\n",
       "      <td>Legenda Brutal Bitter IPA</td>\n",
       "      <td>0.450131</td>\n",
       "      <td>8.2</td>\n",
       "      <td>0.756718</td>\n",
       "      <td>0.454108</td>\n",
       "      <td>-0.000722</td>\n",
       "      <td>-0.000289</td>\n",
       "      <td>1.2</td>\n",
       "      <td>-0.003688</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.600103</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>Baden Baden Witbier</td>\n",
       "      <td>0.445461</td>\n",
       "      <td>4.9</td>\n",
       "      <td>0.761292</td>\n",
       "      <td>0.456853</td>\n",
       "      <td>-0.000240</td>\n",
       "      <td>-0.000096</td>\n",
       "      <td>2.1</td>\n",
       "      <td>-0.011296</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.600103</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>Browar Brodacz MÃ³zg</td>\n",
       "      <td>0.437152</td>\n",
       "      <td>5.7</td>\n",
       "      <td>0.735744</td>\n",
       "      <td>0.441522</td>\n",
       "      <td>-0.000103</td>\n",
       "      <td>-0.000041</td>\n",
       "      <td>1.3</td>\n",
       "      <td>-0.004329</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.600103</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>529</th>\n",
       "      <td>MONYO American Beauty APA</td>\n",
       "      <td>0.436200</td>\n",
       "      <td>5.6</td>\n",
       "      <td>0.737444</td>\n",
       "      <td>0.442542</td>\n",
       "      <td>-0.003306</td>\n",
       "      <td>-0.001322</td>\n",
       "      <td>1.4</td>\n",
       "      <td>-0.005020</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.600103</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>FanÃ¸ Vestkyst</td>\n",
       "      <td>0.434280</td>\n",
       "      <td>5.7</td>\n",
       "      <td>0.730639</td>\n",
       "      <td>0.438458</td>\n",
       "      <td>0.000377</td>\n",
       "      <td>0.000151</td>\n",
       "      <td>1.3</td>\n",
       "      <td>-0.004329</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.600103</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>Basqueland Saison (Lasai'son)</td>\n",
       "      <td>0.433805</td>\n",
       "      <td>5.5</td>\n",
       "      <td>0.732640</td>\n",
       "      <td>0.439659</td>\n",
       "      <td>-0.000227</td>\n",
       "      <td>-0.000091</td>\n",
       "      <td>1.5</td>\n",
       "      <td>-0.005763</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.600103</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>Det Lille Bryggeri Humlemord Tears From Heaven</td>\n",
       "      <td>0.425823</td>\n",
       "      <td>7.4</td>\n",
       "      <td>0.710667</td>\n",
       "      <td>0.426473</td>\n",
       "      <td>-0.000603</td>\n",
       "      <td>-0.000241</td>\n",
       "      <td>0.4</td>\n",
       "      <td>-0.000410</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.600103</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>Kaapse Tess</td>\n",
       "      <td>0.425089</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.726712</td>\n",
       "      <td>0.436101</td>\n",
       "      <td>-0.001917</td>\n",
       "      <td>-0.000767</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.010246</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.600103</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               beer     score  abv  LSH_score  \\\n",
       "639         NÃ¸rrebro Pacific Summer Ale (Ã˜kologisk)  0.460435  5.6   0.777055   \n",
       "424                     Insel-Brauerei Insel Saison  0.455709  5.5   0.772663   \n",
       "508                       Legenda Brutal Bitter IPA  0.450131  8.2   0.756718   \n",
       "82                              Baden Baden Witbier  0.445461  4.9   0.761292   \n",
       "161                             Browar Brodacz MÃ³zg  0.437152  5.7   0.735744   \n",
       "529                       MONYO American Beauty APA  0.436200  5.6   0.737444   \n",
       "292                                   FanÃ¸ Vestkyst  0.434280  5.7   0.730639   \n",
       "92                    Basqueland Saison (Lasai'son)  0.433805  5.5   0.732640   \n",
       "244  Det Lille Bryggeri Humlemord Tears From Heaven  0.425823  7.4   0.710667   \n",
       "451                                     Kaapse Tess  0.425089  5.0   0.726712   \n",
       "\n",
       "     LSH_score_weighted  collab_score  collab_score_weighted  abv_diff  \\\n",
       "639            0.466313     -0.002144              -0.000857       1.4   \n",
       "424            0.463677     -0.005514              -0.002205       1.5   \n",
       "508            0.454108     -0.000722              -0.000289       1.2   \n",
       "82             0.456853     -0.000240              -0.000096       2.1   \n",
       "161            0.441522     -0.000103              -0.000041       1.3   \n",
       "529            0.442542     -0.003306              -0.001322       1.4   \n",
       "292            0.438458      0.000377               0.000151       1.3   \n",
       "92             0.439659     -0.000227              -0.000091       1.5   \n",
       "244            0.426473     -0.000603              -0.000241       0.4   \n",
       "451            0.436101     -0.001917              -0.000767       2.0   \n",
       "\n",
       "     abv_weight  Style bonus  Weight beta notes  \n",
       "639   -0.005020          0.0     0.600103        \n",
       "424   -0.005763          0.0     0.600103        \n",
       "508   -0.003688          0.0     0.600103        \n",
       "82    -0.011296          0.0     0.600103        \n",
       "161   -0.004329          0.0     0.600103        \n",
       "529   -0.005020          0.0     0.600103        \n",
       "292   -0.004329          0.0     0.600103        \n",
       "92    -0.005763          0.0     0.600103        \n",
       "244   -0.000410          0.0     0.600103        \n",
       "451   -0.010246          0.0     0.600103        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a query\n",
    "test_query = \"Light, refreshing bitter beer with a orange taste\"\n",
    "user_name = \"Jerseyislandbeer\"\n",
    "query_embedding = encode_sbert(test_query).reshape(1, -1)\n",
    "beer_recommendations= recommend_beer_B(query_embedding, df_train, user_name, beer_info, abv_desired=7)\n",
    "\n",
    "print(\"Top 5 recommended beers:\")\n",
    "# Set max column width to display full array\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "# Display the DataFrame\n",
    "display(beer_recommendations.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_true = 0\n",
    "num_false = 0\n",
    "for i in range(100):\n",
    "    review_row = df_test_masked.iloc[i]\n",
    "    real_beer = review_row[\"name\"]\n",
    "    query = review_row[\"sbert_embedding\"].reshape(1, -1)\n",
    "    user = review_row[\"reviewer\"]\n",
    "    abv_desired = review_row[\"abv\"]\n",
    "    style_desired = review_row[\"subgenre\"]\n",
    "\n",
    "    beer_recommendations= recommend_beer_B(query_embedding=query, df_train=df_train, user_name=user, beer_info=beer_info, abv_desired=abv_desired, style_desired=style_desired)\n",
    "    if real_beer in beer_recommendations[\"beer\"]:\n",
    "        num_true += 1\n",
    "    else:\n",
    "        num_false +=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>brewery</th>\n",
       "      <th>subgenre</th>\n",
       "      <th>abv</th>\n",
       "      <th>location</th>\n",
       "      <th>rating</th>\n",
       "      <th>average_rating</th>\n",
       "      <th>reviewer</th>\n",
       "      <th>review_date</th>\n",
       "      <th>review_text</th>\n",
       "      <th>algorithm_rating</th>\n",
       "      <th>total_reviews</th>\n",
       "      <th>sbert_embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2187929</th>\n",
       "      <td>1520794</td>\n",
       "      <td>Founders All Day IPA</td>\n",
       "      <td>Founders Brewing Company (Mahou San Miguel)</td>\n",
       "      <td>Session IPA</td>\n",
       "      <td>4.7</td>\n",
       "      <td>ðŸ‡©ðŸ‡°randers, Denmark</td>\n",
       "      <td>3.7</td>\n",
       "      <td>3.59</td>\n",
       "      <td>20107589</td>\n",
       "      <td>August 12, 2016</td>\n",
       "      <td>pour pale without head. piny, light citrus, ar...</td>\n",
       "      <td>90.0</td>\n",
       "      <td>2303</td>\n",
       "      <td>[0.0093215825, -0.04165539, 0.031013042, 0.068...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479957</th>\n",
       "      <td>581970</td>\n",
       "      <td>Westvleteren 12</td>\n",
       "      <td>Abdij St. Sixtus - Westvleteren</td>\n",
       "      <td>Ice Cider/Perry</td>\n",
       "      <td>10.2</td>\n",
       "      <td>ðŸ‡©ðŸ‡°randers, Denmark</td>\n",
       "      <td>3.7</td>\n",
       "      <td>4.42</td>\n",
       "      <td>20107589</td>\n",
       "      <td>September 27, 2013</td>\n",
       "      <td>apples, caramel, roasted malt, liqurish aromas...</td>\n",
       "      <td>100.0</td>\n",
       "      <td>3705</td>\n",
       "      <td>[0.016198197, -0.039563965, 0.054247003, 0.086...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2841653</th>\n",
       "      <td>2264997</td>\n",
       "      <td>Dupont Monk's Stout</td>\n",
       "      <td>Brasserie Dupont</td>\n",
       "      <td>Stout</td>\n",
       "      <td>5.2</td>\n",
       "      <td>ðŸ‡©ðŸ‡°randers, Denmark</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.30</td>\n",
       "      <td>20107589</td>\n",
       "      <td>August 15, 2013</td>\n",
       "      <td>coffee, smoke and bread aromas, fine black app...</td>\n",
       "      <td>51.0</td>\n",
       "      <td>719</td>\n",
       "      <td>[-0.0059644626, -0.052805316, 0.05065915, 0.08...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289833</th>\n",
       "      <td>337086</td>\n",
       "      <td>Thisted Seattle</td>\n",
       "      <td>Thisted Bryghus</td>\n",
       "      <td>Stout</td>\n",
       "      <td>6.5</td>\n",
       "      <td>ðŸ‡©ðŸ‡°randers, Denmark</td>\n",
       "      <td>2.9</td>\n",
       "      <td>3.42</td>\n",
       "      <td>20107589</td>\n",
       "      <td>February 8, 2015</td>\n",
       "      <td>clear coffee aroma, with vanilla notes. appear...</td>\n",
       "      <td>71.0</td>\n",
       "      <td>125</td>\n",
       "      <td>[0.027789045, -0.07606227, 0.057118244, 0.1007...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>549186</th>\n",
       "      <td>658714</td>\n",
       "      <td>Three Floyds Zombie Dust</td>\n",
       "      <td>Three Floyds Brewing Company</td>\n",
       "      <td>Anglo-American Ales</td>\n",
       "      <td>6.2</td>\n",
       "      <td>ðŸ‡©ðŸ‡°randers, Denmark</td>\n",
       "      <td>4.1</td>\n",
       "      <td>4.11</td>\n",
       "      <td>20107589</td>\n",
       "      <td>May 5, 2015</td>\n",
       "      <td>pour pale golden, with a fine white head. ligh...</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1475</td>\n",
       "      <td>[0.025810374, -0.062446844, 0.07448743, 0.0553...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1101968</th>\n",
       "      <td>325014</td>\n",
       "      <td>Tucher Dunkles Hefe Weizen</td>\n",
       "      <td>Tucher BrÃ¤u (Radeberger Group)</td>\n",
       "      <td>Dunkelweizen</td>\n",
       "      <td>5.2</td>\n",
       "      <td>ðŸ‡ºðŸ‡¸Princeton, United States</td>\n",
       "      <td>3.6</td>\n",
       "      <td>3.26</td>\n",
       "      <td>wnhay</td>\n",
       "      <td>September 19, 2005</td>\n",
       "      <td>Poured orange brown with a good tan head.  Aro...</td>\n",
       "      <td>48.0</td>\n",
       "      <td>454</td>\n",
       "      <td>[-0.023349693, 0.0337615, 0.030568456, 0.07432...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2810991</th>\n",
       "      <td>2229220</td>\n",
       "      <td>Saison Dupont</td>\n",
       "      <td>Brasserie Dupont</td>\n",
       "      <td>Saison</td>\n",
       "      <td>6.5</td>\n",
       "      <td>ðŸ‡ºðŸ‡¸Princeton, United States</td>\n",
       "      <td>3.6</td>\n",
       "      <td>3.82</td>\n",
       "      <td>wnhay</td>\n",
       "      <td>November 30, 2004</td>\n",
       "      <td>This beer had a bitter fruit taste which I kin...</td>\n",
       "      <td>98.0</td>\n",
       "      <td>2830</td>\n",
       "      <td>[-0.025270637, -0.013938596, -0.03224327, 0.04...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2488245</th>\n",
       "      <td>1859848</td>\n",
       "      <td>La Chouffe Blonde</td>\n",
       "      <td>Brasserie d'Achouffe (Duvel Moortgat)</td>\n",
       "      <td>Belgian Strong Ale</td>\n",
       "      <td>8.0</td>\n",
       "      <td>ðŸ‡ºðŸ‡¸Princeton, United States</td>\n",
       "      <td>3.2</td>\n",
       "      <td>3.76</td>\n",
       "      <td>wnhay</td>\n",
       "      <td>December 20, 2004</td>\n",
       "      <td>Sampled this.  I thought the taste and aroma w...</td>\n",
       "      <td>97.0</td>\n",
       "      <td>2728</td>\n",
       "      <td>[-0.03302289, -0.030031314, 0.012916914, -0.02...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795399</th>\n",
       "      <td>913821</td>\n",
       "      <td>Harvest Moon Full Moon Pale Ale</td>\n",
       "      <td>Harvest Moon Brewery (NJ)</td>\n",
       "      <td>English Pale Ale</td>\n",
       "      <td>5.6</td>\n",
       "      <td>ðŸ‡ºðŸ‡¸Princeton, United States</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.38</td>\n",
       "      <td>wnhay</td>\n",
       "      <td>April 2, 2006</td>\n",
       "      <td>Tap at the brew pub.  Yellow/golden color with...</td>\n",
       "      <td>71.0</td>\n",
       "      <td>40</td>\n",
       "      <td>[0.067461774, 0.02529345, -0.025659995, 0.0234...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995653</th>\n",
       "      <td>202510</td>\n",
       "      <td>Ayinger FestmÃ¤rzen</td>\n",
       "      <td>Brauerei Aying Franz Inselkammer</td>\n",
       "      <td>Lagers</td>\n",
       "      <td>5.8</td>\n",
       "      <td>ðŸ‡ºðŸ‡¸Princeton, United States</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.61</td>\n",
       "      <td>wnhay</td>\n",
       "      <td>October 20, 2005</td>\n",
       "      <td>The best Oktoberfest I have had to date.  Pour...</td>\n",
       "      <td>91.0</td>\n",
       "      <td>1592</td>\n",
       "      <td>[0.03722477, 0.06627212, 0.12440901, 0.0475447...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4829 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              id                             name  \\\n",
       "2187929  1520794             Founders All Day IPA   \n",
       "479957    581970                  Westvleteren 12   \n",
       "2841653  2264997              Dupont Monk's Stout   \n",
       "289833    337086                  Thisted Seattle   \n",
       "549186    658714         Three Floyds Zombie Dust   \n",
       "...          ...                              ...   \n",
       "1101968   325014       Tucher Dunkles Hefe Weizen   \n",
       "2810991  2229220                    Saison Dupont   \n",
       "2488245  1859848                La Chouffe Blonde   \n",
       "795399    913821  Harvest Moon Full Moon Pale Ale   \n",
       "995653    202510               Ayinger FestmÃ¤rzen   \n",
       "\n",
       "                                             brewery             subgenre  \\\n",
       "2187929  Founders Brewing Company (Mahou San Miguel)          Session IPA   \n",
       "479957               Abdij St. Sixtus - Westvleteren      Ice Cider/Perry   \n",
       "2841653                             Brasserie Dupont                Stout   \n",
       "289833                               Thisted Bryghus                Stout   \n",
       "549186                  Three Floyds Brewing Company  Anglo-American Ales   \n",
       "...                                              ...                  ...   \n",
       "1101968               Tucher BrÃ¤u (Radeberger Group)         Dunkelweizen   \n",
       "2810991                             Brasserie Dupont               Saison   \n",
       "2488245        Brasserie d'Achouffe (Duvel Moortgat)   Belgian Strong Ale   \n",
       "795399                     Harvest Moon Brewery (NJ)     English Pale Ale   \n",
       "995653              Brauerei Aying Franz Inselkammer               Lagers   \n",
       "\n",
       "          abv                    location  rating  average_rating  reviewer  \\\n",
       "2187929   4.7          ðŸ‡©ðŸ‡°randers, Denmark     3.7            3.59  20107589   \n",
       "479957   10.2          ðŸ‡©ðŸ‡°randers, Denmark     3.7            4.42  20107589   \n",
       "2841653   5.2          ðŸ‡©ðŸ‡°randers, Denmark     3.5            3.30  20107589   \n",
       "289833    6.5          ðŸ‡©ðŸ‡°randers, Denmark     2.9            3.42  20107589   \n",
       "549186    6.2          ðŸ‡©ðŸ‡°randers, Denmark     4.1            4.11  20107589   \n",
       "...       ...                         ...     ...             ...       ...   \n",
       "1101968   5.2  ðŸ‡ºðŸ‡¸Princeton, United States     3.6            3.26     wnhay   \n",
       "2810991   6.5  ðŸ‡ºðŸ‡¸Princeton, United States     3.6            3.82     wnhay   \n",
       "2488245   8.0  ðŸ‡ºðŸ‡¸Princeton, United States     3.2            3.76     wnhay   \n",
       "795399    5.6  ðŸ‡ºðŸ‡¸Princeton, United States     3.5            3.38     wnhay   \n",
       "995653    5.8  ðŸ‡ºðŸ‡¸Princeton, United States     4.0            3.61     wnhay   \n",
       "\n",
       "                review_date  \\\n",
       "2187929     August 12, 2016   \n",
       "479957   September 27, 2013   \n",
       "2841653     August 15, 2013   \n",
       "289833     February 8, 2015   \n",
       "549186          May 5, 2015   \n",
       "...                     ...   \n",
       "1101968  September 19, 2005   \n",
       "2810991   November 30, 2004   \n",
       "2488245   December 20, 2004   \n",
       "795399        April 2, 2006   \n",
       "995653     October 20, 2005   \n",
       "\n",
       "                                               review_text algorithm_rating  \\\n",
       "2187929  pour pale without head. piny, light citrus, ar...             90.0   \n",
       "479957   apples, caramel, roasted malt, liqurish aromas...            100.0   \n",
       "2841653  coffee, smoke and bread aromas, fine black app...             51.0   \n",
       "289833   clear coffee aroma, with vanilla notes. appear...             71.0   \n",
       "549186   pour pale golden, with a fine white head. ligh...            100.0   \n",
       "...                                                    ...              ...   \n",
       "1101968  Poured orange brown with a good tan head.  Aro...             48.0   \n",
       "2810991  This beer had a bitter fruit taste which I kin...             98.0   \n",
       "2488245  Sampled this.  I thought the taste and aroma w...             97.0   \n",
       "795399   Tap at the brew pub.  Yellow/golden color with...             71.0   \n",
       "995653   The best Oktoberfest I have had to date.  Pour...             91.0   \n",
       "\n",
       "         total_reviews                                    sbert_embedding  \n",
       "2187929           2303  [0.0093215825, -0.04165539, 0.031013042, 0.068...  \n",
       "479957            3705  [0.016198197, -0.039563965, 0.054247003, 0.086...  \n",
       "2841653            719  [-0.0059644626, -0.052805316, 0.05065915, 0.08...  \n",
       "289833             125  [0.027789045, -0.07606227, 0.057118244, 0.1007...  \n",
       "549186            1475  [0.025810374, -0.062446844, 0.07448743, 0.0553...  \n",
       "...                ...                                                ...  \n",
       "1101968            454  [-0.023349693, 0.0337615, 0.030568456, 0.07432...  \n",
       "2810991           2830  [-0.025270637, -0.013938596, -0.03224327, 0.04...  \n",
       "2488245           2728  [-0.03302289, -0.030031314, 0.012916914, -0.02...  \n",
       "795399              40  [0.067461774, 0.02529345, -0.025659995, 0.0234...  \n",
       "995653            1592  [0.03722477, 0.06627212, 0.12440901, 0.0475447...  \n",
       "\n",
       "[4829 rows x 14 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_masked"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TESTTEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 recommended beers:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>beer</th>\n",
       "      <th>score</th>\n",
       "      <th>abv</th>\n",
       "      <th>LSH_score</th>\n",
       "      <th>LSH_score_weighted</th>\n",
       "      <th>collab_score</th>\n",
       "      <th>collab_score_weighted</th>\n",
       "      <th>abv_diff</th>\n",
       "      <th>abv_weight</th>\n",
       "      <th>notes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>639</th>\n",
       "      <td>NÃ¸rrebro Pacific Summer Ale (Ã˜kologisk)</td>\n",
       "      <td>0.655155</td>\n",
       "      <td>5.6</td>\n",
       "      <td>0.777055</td>\n",
       "      <td>0.660497</td>\n",
       "      <td>-0.002144</td>\n",
       "      <td>-0.000322</td>\n",
       "      <td>1.4</td>\n",
       "      <td>-0.005020</td>\n",
       "      <td>[orange, oranges, bitter, citrus, citrusy, sweetness, ale, bitterness, grapefruit, fruitiness]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424</th>\n",
       "      <td>Insel-Brauerei Insel Saison</td>\n",
       "      <td>0.650174</td>\n",
       "      <td>5.5</td>\n",
       "      <td>0.772663</td>\n",
       "      <td>0.656764</td>\n",
       "      <td>-0.005514</td>\n",
       "      <td>-0.000827</td>\n",
       "      <td>1.5</td>\n",
       "      <td>-0.005763</td>\n",
       "      <td>[orange, tasting, bitter, citrus, sweetness, ale, wine, bitterness, sour, fruit]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508</th>\n",
       "      <td>Legenda Brutal Bitter IPA</td>\n",
       "      <td>0.639414</td>\n",
       "      <td>8.2</td>\n",
       "      <td>0.756718</td>\n",
       "      <td>0.643210</td>\n",
       "      <td>-0.000722</td>\n",
       "      <td>-0.000108</td>\n",
       "      <td>1.2</td>\n",
       "      <td>-0.003688</td>\n",
       "      <td>[orange, bitter, citrus, citrusy, sweetness, ipa, alcohol, bitterness, grape, grapefruit]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>Baden Baden Witbier</td>\n",
       "      <td>0.635766</td>\n",
       "      <td>4.9</td>\n",
       "      <td>0.761292</td>\n",
       "      <td>0.647098</td>\n",
       "      <td>-0.000240</td>\n",
       "      <td>-0.000036</td>\n",
       "      <td>2.1</td>\n",
       "      <td>-0.011296</td>\n",
       "      <td>[orange, oranges, bitter, citrus, sweetness, ale, bitterness, ales, drinkability, sour]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>529</th>\n",
       "      <td>MONYO American Beauty APA</td>\n",
       "      <td>0.621311</td>\n",
       "      <td>5.6</td>\n",
       "      <td>0.737444</td>\n",
       "      <td>0.626828</td>\n",
       "      <td>-0.003306</td>\n",
       "      <td>-0.000496</td>\n",
       "      <td>1.4</td>\n",
       "      <td>-0.005020</td>\n",
       "      <td>[orange, tasting, bitter, citrus, citrusy, sweetness, ale, bitterness, grapefruit, sour]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>Browar Brodacz MÃ³zg</td>\n",
       "      <td>0.621038</td>\n",
       "      <td>5.7</td>\n",
       "      <td>0.735744</td>\n",
       "      <td>0.625382</td>\n",
       "      <td>-0.000103</td>\n",
       "      <td>-0.000015</td>\n",
       "      <td>1.3</td>\n",
       "      <td>-0.004329</td>\n",
       "      <td>[orange, bitternes, bitter, citrus, citrusy, ale, bitterness, ales, sour, drinkable]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>Basqueland Saison (Lasai'son)</td>\n",
       "      <td>0.616947</td>\n",
       "      <td>5.5</td>\n",
       "      <td>0.732640</td>\n",
       "      <td>0.622744</td>\n",
       "      <td>-0.000227</td>\n",
       "      <td>-0.000034</td>\n",
       "      <td>1.5</td>\n",
       "      <td>-0.005763</td>\n",
       "      <td>[orange, bitter, citrus, sweetness, bitterness, beery, aromas, sour, fruit, spicy]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>FanÃ¸ Vestkyst</td>\n",
       "      <td>0.616771</td>\n",
       "      <td>5.7</td>\n",
       "      <td>0.730639</td>\n",
       "      <td>0.621043</td>\n",
       "      <td>0.000377</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>1.3</td>\n",
       "      <td>-0.004329</td>\n",
       "      <td>[orange, bitter, citrus, sweetness, ipa, ale, bitterness, grapefruit, fruit, spicy]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>Kaapse Tess</td>\n",
       "      <td>0.607172</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.726712</td>\n",
       "      <td>0.617705</td>\n",
       "      <td>-0.001917</td>\n",
       "      <td>-0.000288</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.010246</td>\n",
       "      <td>[orange, bitter, citrus, sweetness, wine, bitterness, grape, grapefruit, fruitiness, sour]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>653</th>\n",
       "      <td>Orca / Heidenpeters / Ale Mania Head in the Clouds</td>\n",
       "      <td>0.606479</td>\n",
       "      <td>3.9</td>\n",
       "      <td>0.742507</td>\n",
       "      <td>0.631131</td>\n",
       "      <td>-0.000244</td>\n",
       "      <td>-0.000037</td>\n",
       "      <td>3.1</td>\n",
       "      <td>-0.024615</td>\n",
       "      <td>[orange, bitter, citrus, bitterness, grapefruit, sour, lager, phenolic, coffee, freshness]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   beer     score  abv  \\\n",
       "639             NÃ¸rrebro Pacific Summer Ale (Ã˜kologisk)  0.655155  5.6   \n",
       "424                         Insel-Brauerei Insel Saison  0.650174  5.5   \n",
       "508                           Legenda Brutal Bitter IPA  0.639414  8.2   \n",
       "82                                  Baden Baden Witbier  0.635766  4.9   \n",
       "529                           MONYO American Beauty APA  0.621311  5.6   \n",
       "161                                 Browar Brodacz MÃ³zg  0.621038  5.7   \n",
       "92                        Basqueland Saison (Lasai'son)  0.616947  5.5   \n",
       "292                                       FanÃ¸ Vestkyst  0.616771  5.7   \n",
       "451                                         Kaapse Tess  0.607172  5.0   \n",
       "653  Orca / Heidenpeters / Ale Mania Head in the Clouds  0.606479  3.9   \n",
       "\n",
       "     LSH_score  LSH_score_weighted  collab_score  collab_score_weighted  \\\n",
       "639   0.777055            0.660497     -0.002144              -0.000322   \n",
       "424   0.772663            0.656764     -0.005514              -0.000827   \n",
       "508   0.756718            0.643210     -0.000722              -0.000108   \n",
       "82    0.761292            0.647098     -0.000240              -0.000036   \n",
       "529   0.737444            0.626828     -0.003306              -0.000496   \n",
       "161   0.735744            0.625382     -0.000103              -0.000015   \n",
       "92    0.732640            0.622744     -0.000227              -0.000034   \n",
       "292   0.730639            0.621043      0.000377               0.000056   \n",
       "451   0.726712            0.617705     -0.001917              -0.000288   \n",
       "653   0.742507            0.631131     -0.000244              -0.000037   \n",
       "\n",
       "     abv_diff  abv_weight  \\\n",
       "639       1.4   -0.005020   \n",
       "424       1.5   -0.005763   \n",
       "508       1.2   -0.003688   \n",
       "82        2.1   -0.011296   \n",
       "529       1.4   -0.005020   \n",
       "161       1.3   -0.004329   \n",
       "92        1.5   -0.005763   \n",
       "292       1.3   -0.004329   \n",
       "451       2.0   -0.010246   \n",
       "653       3.1   -0.024615   \n",
       "\n",
       "                                                                                              notes  \n",
       "639  [orange, oranges, bitter, citrus, citrusy, sweetness, ale, bitterness, grapefruit, fruitiness]  \n",
       "424                [orange, tasting, bitter, citrus, sweetness, ale, wine, bitterness, sour, fruit]  \n",
       "508       [orange, bitter, citrus, citrusy, sweetness, ipa, alcohol, bitterness, grape, grapefruit]  \n",
       "82          [orange, oranges, bitter, citrus, sweetness, ale, bitterness, ales, drinkability, sour]  \n",
       "529        [orange, tasting, bitter, citrus, citrusy, sweetness, ale, bitterness, grapefruit, sour]  \n",
       "161            [orange, bitternes, bitter, citrus, citrusy, ale, bitterness, ales, sour, drinkable]  \n",
       "92               [orange, bitter, citrus, sweetness, bitterness, beery, aromas, sour, fruit, spicy]  \n",
       "292             [orange, bitter, citrus, sweetness, ipa, ale, bitterness, grapefruit, fruit, spicy]  \n",
       "451      [orange, bitter, citrus, sweetness, wine, bitterness, grape, grapefruit, fruitiness, sour]  \n",
       "653      [orange, bitter, citrus, bitterness, grapefruit, sour, lager, phenolic, coffee, freshness]  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def recommend_beer(query_embedding, df_train, user_name, abv_desired, n_clusters=15):    \n",
    "    # Query the LSH index\n",
    "    candidates = lsh.query(query_embedding)\n",
    "\n",
    "    # Filter bucket vectors and metadata\n",
    "    bucket_data = df_train[df_train[\"id\"].isin(list(candidates[0]))]\n",
    "    bucket_vectors = np.vstack(bucket_data[\"sbert_embedding\"].to_numpy())\n",
    "    \n",
    "    # Extract subgenre information\n",
    "    subgenres = bucket_data[\"subgenre\"].values  # Adjust column name as necessary\n",
    "    \n",
    "    # Perform clustering on bucket vectors\n",
    "    kmeans = KMeans(n_clusters=n_clusters, n_init='auto', random_state=42)\n",
    "    cluster_labels = kmeans.fit_predict(bucket_vectors)\n",
    "    \n",
    "    # Assign query to the nearest cluster\n",
    "    query_cluster = kmeans.predict(query_embedding)[0]\n",
    "    \n",
    "    perplexities = [50]\n",
    "    n_iters = [10000]\n",
    "    learning_rates = [100, 200]\n",
    "    \n",
    "    param_combinations = [(p, n, lr) for p in perplexities for n in n_iters for lr in learning_rates]\n",
    "    \n",
    "    #for perplexity, n_iter, learning_rate in param_combinations:\n",
    "    #    plot_bucket(bucket_vectors, cluster_labels, subgenres, perplexity, n_iter, learning_rate)\n",
    "        \n",
    "    # Filter beers in the same cluster as the query\n",
    "    cluster_indices = np.where(cluster_labels == query_cluster)[0]\n",
    "    cluster_vectors = bucket_vectors[cluster_indices]\n",
    "    cluster_beers = bucket_data.iloc[cluster_indices]\n",
    "    \n",
    "    # Compute similarities within the selected cluster\n",
    "    sims = cosine_similarity(query_embedding, cluster_vectors)[0]\n",
    "\n",
    "    # Perform collaborative filtering\n",
    "    predcicted_rating_user = collab_df.loc[user_name]\n",
    "    \n",
    "    beer_LSH = pd.DataFrame({\n",
    "        'similarity': sims,\n",
    "        'beer': cluster_beers[\"name\"].values,  # Adjust column name if necessary\n",
    "    })\n",
    "    \n",
    "    LSH_score = beer_LSH.groupby('beer')['similarity'].mean()\n",
    "    \n",
    "    collab_filtering_scores = predcicted_rating_user[LSH_score.index.tolist()]\n",
    "    \n",
    "    # Penalise difference in abv by using a nonlinear function penalising greater differences more\n",
    "    abv = beer_info.loc[LSH_score.index.tolist()][\"abv\"]\n",
    "\n",
    "    alpha = 0.05\n",
    "    if abv_desired == 0:\n",
    "        abv_weight = -2 * abs(abv - abv_desired)\n",
    "    else:\n",
    "        abv_weight = -alpha * ((abv - abv_desired)**2) / (abv_desired**1.5 + 1)\n",
    "    \n",
    "\n",
    "    # Combine weights and scores\n",
    "    weighted_score = (\n",
    "        0.85 * LSH_score +\n",
    "        0.15 * collab_filtering_scores +\n",
    "        abv_weight\n",
    "    )\n",
    "    \n",
    "    # Create final DataFrame\n",
    "    beer_weighted_score = pd.DataFrame({\n",
    "        'beer': LSH_score.index,\n",
    "        'score': weighted_score,\n",
    "        'abv': abv.values,\n",
    "        'LSH_score': LSH_score.values,\n",
    "        'LSH_score_weighted': LSH_score.values * 0.85,\n",
    "        'collab_score': collab_filtering_scores.values,\n",
    "        'collab_score_weighted': collab_filtering_scores.values * 0.15,\n",
    "        'abv_diff': abs(abv.values - abv_desired),\n",
    "        'abv_weight': abv_weight.values\n",
    "    })\n",
    "    \n",
    "    # Remove index of weighted score and keep the beer name as a column\n",
    "    beer_weighted_score.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    # Get the 10 beers with the highest weighted scores\n",
    "    beer_weighted_score = beer_weighted_score.sort_values(by='score', ascending=False).head(10)\n",
    "    \n",
    "    # Apply getThemes to each beer in the DataFrame\n",
    "    beer_weighted_score['notes'] = beer_weighted_score['beer'].apply(lambda x: getThemes(df_train, x, query_embedding))\n",
    "\n",
    "\n",
    "    return beer_weighted_score.sort_values(by='score', ascending=False)\n",
    "    \n",
    "\n",
    "# Create a query\n",
    "test_query = \"Light, refreshing bitter beer with a orange taste\"\n",
    "user_name = \"Jerseyislandbeer\"\n",
    "query_embedding = encode_sbert(test_query).reshape(1, -1)\n",
    "beer_recommendations= recommend_beer(query_embedding, df_train, user_name, 7)\n",
    "\n",
    "print(\"Top 5 recommended beers:\")\n",
    "# Set max column width to display full array\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "# Display the DataFrame\n",
    "display(beer_recommendations.head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes for improvement\n",
    "Add better stop-words, flavor, flavour, flavors etc.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation settup"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
