{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from collections import defaultdict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size after drop_duplicates:  1157819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ql/h53w_qjs60509nsf4jbr01c00000gn/T/ipykernel_22617/2960229199.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtered['rating'] = pd.to_numeric(df_filtered['rating'], errors='coerce')  # Set erros to NaN\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size after drop rating NA:  1157807\n",
      "Size after drop abv NA:  1154739\n"
     ]
    }
   ],
   "source": [
    "# Load data and preprocess\n",
    "df = pd.read_pickle('encoded_beers_SBERT.pkl')\n",
    "\n",
    "df_filtered = df.drop_duplicates([\"name\", \"reviewer\", \"review_text\"]) # Remove duplicate entries\n",
    "print(\"Size after drop_duplicates: \", len(df_filtered))\n",
    "\n",
    "#convert numeric values to floats\n",
    "df_filtered['rating'] = pd.to_numeric(df_filtered['rating'], errors='coerce')  # Set erros to NaN\n",
    "df_filtered = df_filtered.dropna(subset=['rating'])  # Drop rows where 'rating' is NaN\n",
    "print(\"Size after drop rating NA: \", len(df_filtered))\n",
    "df_filtered['abv'] = pd.to_numeric(df_filtered['abv'].str.rstrip('%'), errors='coerce') \n",
    "df_filtered = df_filtered.dropna(subset=['abv'])\n",
    "print(\"Size after drop abv NA: \", len(df_filtered))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### Dataset Summary ###\n",
      "Total reviewers sampled: 100\n",
      "Training set size: (1132916, 14)\n",
      "Test set size: (5746, 14)\n"
     ]
    }
   ],
   "source": [
    "# Create test set\n",
    "\n",
    "# Randomly sample 100 reviewers from the dataset\n",
    "sampled_reviewers = df_filtered[\"reviewer\"].sample(n=100, random_state=7)\n",
    "# Get reviews from the sampled reviewers\n",
    "df_test = df_filtered[df_filtered['reviewer'].isin(sampled_reviewers)]\n",
    "# Remove the sampled reviews\n",
    "#df_filtered = df_filtered[~df_filtered['reviewer'].isin(sampled_reviewers)]\n",
    "\n",
    "# Group by reviewer to get each user's beers\n",
    "df_test_grouped = df_test.groupby('reviewer')\n",
    "\n",
    "# Randomly mask 10% of beers for each reviewer\n",
    "test_set_masked = []\n",
    "\n",
    "for reviewer, group in df_test_grouped:\n",
    "    # Calculate how many beers to mask (10% of the beers this reviewer has rated or 1 in case 10 % is less than 1)\n",
    "    num_to_mask = max(int(len(group) * 0.10), 1)\n",
    "    \n",
    "    # Sample 10% of the beers for this reviewer\n",
    "    masked_group = group.sample(n=num_to_mask, random_state=7)\n",
    "    test_set_masked.append(masked_group)\n",
    "    \n",
    "df_test_masked = pd.concat(test_set_masked)\n",
    "\n",
    "# remove test reviews from train data\n",
    "df_filtered = df_filtered.drop(df_test_masked.index)\n",
    "\n",
    "# Display dataset summaries\n",
    "print(\"\\n### Dataset Summary ###\")\n",
    "print(f\"Total reviewers sampled: {len(sampled_reviewers)}\")\n",
    "print(f\"Training set size: {df_filtered.shape}\")\n",
    "print(f\"Test set size: {df_test_masked.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe for retrieving beer information\n",
    "beer_info = df_filtered[['name', 'abv', 'subgenre']]\n",
    "\n",
    "# Drop duplicate rows based on the 'name' column (i.e. beers)\n",
    "beer_info = beer_info.drop_duplicates(subset='name')\n",
    "\n",
    "beer_info.set_index('name', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create locality-sensitive hashing (LSH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make LSH\n",
    "# Extract vectors and identifiers\n",
    "vectors = np.vstack(df_filtered[\"sbert_embedding\"].values)  # Combine embeddings into a 2D array\n",
    "identifiers = df_filtered.index.tolist()  # Use review IDs as identifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_hyperplanes(dim, num_hash_functions):\n",
    "    \"\"\"\n",
    "    Generate random hyperplanes for hash functions.\n",
    "    \n",
    "    Parameters:\n",
    "    - dim: Dimensionality of the embeddings.\n",
    "    - num_hash_functions: Number of hash functions per table.\n",
    "    \n",
    "    Returns:\n",
    "    - A matrix of shape (num_hash_functions, dim) where each row is a hyperplane.\n",
    "    \"\"\"\n",
    "    return np.random.randn(num_hash_functions, dim)\n",
    "\n",
    "def hash_vectors(vectors, hyperplanes):\n",
    "    \"\"\"\n",
    "    Hash a batch of vectors using a set of hyperplanes.\n",
    "\n",
    "    Parameters:\n",
    "    - vectors: Input vectors (2D array of shape [n_samples, d]).\n",
    "    - hyperplanes: Matrix of hyperplanes (2D array of shape [k, d]).\n",
    "\n",
    "    Returns:\n",
    "    - A matrix of binary hash values (shape [n_samples, k]).\n",
    "    \"\"\"\n",
    "    # Compute dot products and return binary hash values\n",
    "    return (np.dot(vectors, hyperplanes.T) > 0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build LSH framework\n",
    "class LSHVectorized:\n",
    "    def __init__(self, d, k, L):\n",
    "        \"\"\"\n",
    "        Initialize the LSH scheme with vectorized support.\n",
    "\n",
    "        Parameters:\n",
    "        - d: Dimensionality of the input vectors.\n",
    "        - k: Number of hash functions per table.\n",
    "        - L: Number of hash tables.\n",
    "        \"\"\"\n",
    "        self.L = L\n",
    "        self.tables = [defaultdict(list) for _ in range(L)]\n",
    "        self.hyperplanes = [generate_hyperplanes(d, k) for _ in range(L)]\n",
    "\n",
    "    def add_vectors(self, vectors, identifiers):\n",
    "        \"\"\"\n",
    "        Add a batch of vectors to the LSH index.\n",
    "\n",
    "        Parameters:\n",
    "        - vectors: Input vectors (2D array of shape [n_samples, d]).\n",
    "        - identifiers: A list of unique identifiers for the vectors.\n",
    "        \"\"\"\n",
    "        for table, hyperplanes in zip(self.tables, self.hyperplanes):\n",
    "            # Compute hash values for all vectors at once\n",
    "            hash_values = hash_vectors(vectors, hyperplanes)\n",
    "            \n",
    "            # Convert binary hash values to tuples for dictionary keys\n",
    "            hash_keys = [tuple(h) for h in hash_values]\n",
    "            \n",
    "            # Add vectors to their corresponding buckets\n",
    "            for identifier, key in zip(identifiers, hash_keys):\n",
    "                table[key].append(identifier)\n",
    "\n",
    "    def query(self, vectors):\n",
    "        \"\"\"\n",
    "        Query the LSH index to find similar items for a batch of vectors.\n",
    "\n",
    "        Parameters:\n",
    "        - vectors: Query vectors (2D array of shape [n_samples, d]).\n",
    "\n",
    "        Returns:\n",
    "        - A list of sets, where each set contains the candidates for a query vector.\n",
    "        \"\"\"\n",
    "        candidates = [set() for _ in range(len(vectors))]\n",
    "        for table, hyperplanes in zip(self.tables, self.hyperplanes):\n",
    "            # Compute hash values for all query vectors\n",
    "            hash_values = hash_vectors(vectors, hyperplanes)\n",
    "            \n",
    "            # Convert binary hash values to tuples for dictionary keys\n",
    "            hash_keys = [tuple(h) for h in hash_values]\n",
    "            \n",
    "            # Retrieve candidates for each query\n",
    "            for i, key in enumerate(hash_keys):\n",
    "                candidates[i].update(table.get(key, []))\n",
    "        return candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Run LSH ##\n",
    "# Initialize LSH scheme\n",
    "d = 384\n",
    "k = 14 \n",
    "L = 7\n",
    "\n",
    "lsh = LSHVectorized(d, k, L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add vectors to the LSH index\n",
    "lsh.add_vectors(vectors, identifiers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Collaborative filtering (CF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO lÃ¦s hele igennem og lav kommentarer\n",
    "def predict_ratings_user_based(user_item_matrix, similarity_matrix):\n",
    "       # TODO Hvordan hÃ¥ndterer vi Ã¸l personen allerede har rated\n",
    "\n",
    "    # Compute predictions\n",
    "    similarity_sum = np.abs(similarity_matrix).sum(axis=1)[:, None]\n",
    "    pred = pred = np.dot(similarity_matrix, user_item_matrix) / (similarity_sum + 1e-8)\n",
    "\n",
    "    return pred\n",
    "\n",
    "\n",
    "def collaborative_filtering(df, drop_cols = [\"brewery\", \"subgenre\", \"abv\", \"sbert_embedding\"]):\n",
    "    df_colab = df\n",
    "\n",
    "\n",
    "    user_item_matrix = df_colab.pivot_table(\n",
    "    index=\"reviewer\",     # Rows: Reviewers\n",
    "    columns=\"name\",       # Columns: Beer names\n",
    "    values=\"rating\",      # Values: Ratings\n",
    "    fill_value=0          # Fill missing ratings with 0\n",
    "    )\n",
    "    \n",
    "\n",
    "    user_means = user_item_matrix.replace(0, np.nan).mean(axis=1).fillna(0).to_numpy()\n",
    "    \n",
    "    user_item_np = np.where(user_item_matrix != 0, user_item_matrix - user_means[:, None], 0)\n",
    "\n",
    "    user_item_matrix = pd.DataFrame(user_item_np, index=user_item_matrix.index, columns=user_item_matrix.columns)\n",
    "\n",
    "\n",
    "    # Compute cosine similarity\n",
    "    #cosine_similarity = compute_cosine_similarity_manual(utility_matrix.values)\n",
    "    cosine_similarity_matrix = cosine_similarity(user_item_matrix)\n",
    "    \n",
    "    # Predict ratings\n",
    "    predicted_ratings = predict_ratings_user_based(user_item_matrix, cosine_similarity_matrix)\n",
    "\n",
    "    pr_df = pd.DataFrame(predicted_ratings, index=user_item_matrix.index, columns=user_item_matrix.columns)\n",
    "   \n",
    "    return pr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make collaborative filtering and achieve \"predicted\" normalised rating for each beer for each user\n",
    "pr_df = collaborative_filtering(df_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    33526.000000\n",
       "mean        43.932347\n",
       "std         49.235832\n",
       "min          0.008544\n",
       "25%          0.111073\n",
       "50%          0.845865\n",
       "75%        100.000000\n",
       "max        100.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Caculate fraction of beers per user which is zero\n",
    "zero_percentage = (pr_df == 0).mean(axis=1) * 100\n",
    "zero_percentage.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make reccomendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_vectors = np.vstack(df_test_masked[\"sbert_embedding\"].values) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                                                            2233306\n",
       "name                                         Vrijstaat Vanmol Janimal\n",
       "brewery                                      Vrijstaat Vanmol Brewing\n",
       "subgenre                                                  Session IPA\n",
       "abv                                                               3.3\n",
       "location                                         ðŸ‡§ðŸ‡ªAntwerpen, Belgium\n",
       "rating                                                            3.9\n",
       "average_rating                                                   3.57\n",
       "reviewer                                                      77ships\n",
       "review_date                                               May 7, 2017\n",
       "review_text         Thank you Kraddel! 330 ml. bottle sampled @ In...\n",
       "algorithm_rating                                                 89.0\n",
       "total_reviews                                                      49\n",
       "sbert_embedding     [-0.01595407, 0.010769329, -0.020604532, -0.01...\n",
       "Name: 1124265, dtype: object"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get a single example that we will try and reccomend a beer to based on review_text, abv, and subgenre\n",
    "df_test_masked.iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4508"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First use LSH to find similar candidates\n",
    "test_vector = test_vectors[1].reshape(1, -1)  # Use the first vector as an example query\n",
    "candidates = lsh.query(test_vector)\n",
    "len(candidates[0]) # Check number of reviews in bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of fifferent beer in bucket:  1475\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of fifferent beer in bucket: \", len(set(df_filtered[df_filtered[\"id\"].isin(list(candidates[0]))][\"name\"]))) \n",
    "bucket_vectors = df_filtered[df_filtered[\"id\"].isin(list(candidates[0]))][\"sbert_embedding\"]\n",
    "bucket_vectors = np.vstack(bucket_vectors.to_numpy())\n",
    "# Calculate the similarity between each word embedding vector in bucket and example review_text:\n",
    "similarities = cosine_similarity(test_vector, bucket_vectors)[0]\n",
    "\n",
    "beer_similarities = pd.DataFrame({\n",
    "    'similarity': similarities,\n",
    "    'beer': df_filtered[df_filtered[\"id\"].isin(list(candidates[0]))][\"name\"].values \n",
    "})\n",
    "# Calculate average similarity between promt (i.e. example review_text) and each beer in bucket\n",
    "average_similarities_per_beer = beer_similarities.groupby('beer')['similarity'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "beer\n",
       "5th Element BONNER                 0.689045\n",
       "Domaine Neige Bulle de Neige       0.674373\n",
       "Kehrwieder Ã¼.NN IPA alkoholfrei    0.674135\n",
       "Birrificio Rurale 405040           0.673291\n",
       "Craftwerk Holy Cowl                0.669864\n",
       "Name: similarity, dtype: float32"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show most similar beers based on LSH\n",
    "average_similarities_per_beer.nlargest(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next use collaborative filtering output to get cf-scores\n",
    "cf_scores = pr_df[average_similarities_per_beer.index.tolist()] # Only extract similarities for the beers from the LSH bucket\n",
    "cf_scores_ex = cf_scores.loc[\"77ships\"] # Get cf_scores for our example user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name\n",
       "Westvleteren 12                            0.258554\n",
       "Trappistes Rochefort 10                    0.243262\n",
       "AleSmith Speedway Stout                    0.206176\n",
       "Goose Island Bourbon County Stout          0.180837\n",
       "Founders KBS (Kentucky Breakfast Stout)    0.176311\n",
       "Name: 77ships, dtype: float64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show most similar beers based on CF\n",
    "cf_scores_ex.nlargest(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Combine CF and LSH + extra attributes into a final score**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = 0.4 + 0.006*zero_percentage.loc[\"77ships\"] # Linear function to scale beta such that persons with few reviews rely more on LSH and vice versa\n",
    "total_score = beta*average_similarities_per_beer  + (1-beta)* cf_scores_ex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "beer\n",
       "Westvleteren 12            0.360347\n",
       "Trappistes Rochefort 10    0.333341\n",
       "AleSmith Speedway Stout    0.313445\n",
       "St. Bernardus Abt 12       0.305852\n",
       "Struise Pannepot           0.302391\n",
       "dtype: float64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_score.nlargest(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Penalise difference in abv by using a nonlinear function penalising greater differences more\n",
    "abv = beer_info.loc[average_similarities_per_beer.index.tolist()][\"abv\"]\n",
    "abv_2 = df_test_masked.iloc[1][\"abv\"] # Extract from example\n",
    "alpha = 0.01\n",
    "\n",
    "if abv_2 == 0:\n",
    "    total_score = total_score - 2 * abs(abv - abv_2) # Ensure zero percent alchol\n",
    "else:\n",
    "    total_score = total_score - alpha * ((abv - abv_2)**2) / (abv_2**1.5 + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "beer\n",
       "Westvleteren 12                   0.292282\n",
       "Ayinger Celebrator Doppelbock     0.277752\n",
       "5th Element BONNER                0.274321\n",
       "3 Fonteinen Schaarbeekse Kriek    0.273181\n",
       "Westvleteren 8                    0.268034\n",
       "dtype: float64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_score.nlargest(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add bonus for match in style\n",
    "relevant_styles = beer_info.loc[average_similarities_per_beer.index.tolist()][\"subgenre\"]\n",
    "style = df_test_masked.iloc[1][\"subgenre\"] # Extract from example\n",
    "style_mask = relevant_styles == style\n",
    "style_bonus = np.zeros(len(total_score))\n",
    "style_bonus[style_mask] = 0.05\n",
    "\n",
    "total_score += style_bonus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "beer\n",
       "Pulfer Landsky Session IPA       0.307425\n",
       "Kees Session IPA                 0.301117\n",
       "Westvleteren 12                  0.292282\n",
       "Oersoep Hopfather                0.289826\n",
       "LOC Dinky Mosaic                 0.279713\n",
       "Ayinger Celebrator Doppelbock    0.277752\n",
       "Bevog Zo Session IPA             0.276543\n",
       "Garage Triangles                 0.275013\n",
       "5th Element BONNER               0.274321\n",
       "Mikkeller Session IPA Nelson     0.274057\n",
       "dtype: float64"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print final scores which are the resulting beer reccomendations\n",
    "total_score.nlargest(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation settup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def give_reccomendation(lsh, test_vector, df_filtered, pr_df, user, beer_info, abv_2, style):\n",
    "    candidates = lsh.query(test_vector)\n",
    "    bucket_vectors = df_filtered[df_filtered[\"id\"].isin(list(candidates[0]))][\"sbert_embedding\"]\n",
    "    bucket_vectors = np.vstack(bucket_vectors.to_numpy())\n",
    "\n",
    "    # Calculate the similarity between each word embedding vector in bucket and example review_text:\n",
    "    similarities = cosine_similarity(test_vector, bucket_vectors)[0]\n",
    "\n",
    "    beer_similarities = pd.DataFrame({\n",
    "        'similarity': similarities,\n",
    "        'beer': df_filtered[df_filtered[\"id\"].isin(list(candidates[0]))][\"name\"].values \n",
    "    })\n",
    "    # Calculate average similarity between prompt (i.e. example review_text) and each beer in bucket\n",
    "    average_similarities_per_beer = beer_similarities.groupby('beer')['similarity'].mean()\n",
    "\n",
    "    # Next use collaborative filtering output to get cf-scores\n",
    "    cf_scores = pr_df[average_similarities_per_beer.index.tolist()] # Only extract similarities for the beers from the LSH bucket\n",
    "    cf_scores_ex = cf_scores.loc[user] # Get cf_scores for our example user\n",
    "\n",
    "    beta = 0.4 + 0.006*zero_percentage.loc[user] # Linear function to scale beta such that persons with few reviews rely more on LSH and vice versa\n",
    "    total_score = beta*average_similarities_per_beer  + (1-beta)* cf_scores_ex\n",
    "\n",
    "    # Penalise difference in abv by using a nonlinear function penalising greater differences more\n",
    "    abv = beer_info.loc[average_similarities_per_beer.index.tolist()][\"abv\"]\n",
    "    alpha = 0.01\n",
    "    if abv_2 == None:\n",
    "        total_score = total_score\n",
    "    elif abv_2 == 0:\n",
    "        total_score = total_score - 2 * abs(abv - abv_2) # Ensure zero percent alchol\n",
    "    else:\n",
    "        total_score = total_score - alpha * ((abv - abv_2)**2) / (abv_2**1.5 + 1)\n",
    "    \n",
    "    \n",
    "    # Add bonus for match in style\n",
    "    if style:\n",
    "        relevant_styles = beer_info.loc[average_similarities_per_beer.index.tolist()][\"subgenre\"]\n",
    "        style_mask = relevant_styles == style\n",
    "        style_bonus = np.zeros(len(total_score))\n",
    "        style_bonus[style_mask] = 0.05\n",
    "\n",
    "        total_score += style_bonus\n",
    "        \n",
    "    return total_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Make code to loop through examples"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
