{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data and preprocess\n",
    "df = pd.read_pickle('encoded_beers_SBERT.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size after drop_duplicates:  1157819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ql/h53w_qjs60509nsf4jbr01c00000gn/T/ipykernel_11549/84345811.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtered['rating'] = pd.to_numeric(df_filtered['rating'], errors='coerce')  # set erros to NaN\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size after drop rating NA:  1157807\n",
      "Size after drop abv NA:  1154739\n"
     ]
    }
   ],
   "source": [
    "df_filtered = df.drop_duplicates([\"name\", \"reviewer\", \"review_text\"])\n",
    "print(\"Size after drop_duplicates: \", len(df_filtered))\n",
    "df_filtered['rating'] = pd.to_numeric(df_filtered['rating'], errors='coerce')  # set erros to NaN\n",
    "df_filtered = df_filtered.dropna(subset=['rating'])  # Drop rows where 'rating' is NaN\n",
    "print(\"Size after drop rating NA: \", len(df_filtered))\n",
    "df_filtered['abv'] = pd.to_numeric(df_filtered['abv'].str.rstrip('%'), errors='coerce') \n",
    "df_filtered = df_filtered.dropna(subset=['abv'])\n",
    "print(\"Size after drop abv NA: \", len(df_filtered))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "# TODO: Remove duplicates, lav ny id kollonne, lav ratings og abv om til floats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop_cols = [\"brewery\", \"subgenre\", \"abv\", \"sbert_embedding\"]\n",
    "#df_collab = df.drop(drop_cols, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make LSH\n",
    "# Extract vectors and identifiers\n",
    "vectors = np.vstack(df_filtered[\"sbert_embedding\"].values)  # Combine embeddings into a 2D array\n",
    "identifiers = df_filtered.index.tolist()  # Use review IDs as identifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_hyperplanes(dim, num_hash_functions):\n",
    "    \"\"\"\n",
    "    Generate random hyperplanes for hash functions.\n",
    "    \n",
    "    Parameters:\n",
    "    - dim: Dimensionality of the embeddings.\n",
    "    - num_hash_functions: Number of hash functions per table.\n",
    "    \n",
    "    Returns:\n",
    "    - A matrix of shape (num_hash_functions, dim) where each row is a hyperplane.\n",
    "    \"\"\"\n",
    "    return np.random.randn(num_hash_functions, dim)\n",
    "\n",
    "def hash_vectors(vectors, hyperplanes):\n",
    "    \"\"\"\n",
    "    Hash a batch of vectors using a set of hyperplanes.\n",
    "\n",
    "    Parameters:\n",
    "    - vectors: Input vectors (2D array of shape [n_samples, d]).\n",
    "    - hyperplanes: Matrix of hyperplanes (2D array of shape [k, d]).\n",
    "\n",
    "    Returns:\n",
    "    - A matrix of binary hash values (shape [n_samples, k]).\n",
    "    \"\"\"\n",
    "    # Compute dot products and return binary hash values\n",
    "    return (np.dot(vectors, hyperplanes.T) > 0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build LSH framework\n",
    "from collections import defaultdict\n",
    "\n",
    "class LSHVectorized:\n",
    "    def __init__(self, d, k, L):\n",
    "        \"\"\"\n",
    "        Initialize the LSH scheme with vectorized support.\n",
    "\n",
    "        Parameters:\n",
    "        - d: Dimensionality of the input vectors.\n",
    "        - k: Number of hash functions per table.\n",
    "        - L: Number of hash tables.\n",
    "        \"\"\"\n",
    "        self.L = L\n",
    "        self.tables = [defaultdict(list) for _ in range(L)]\n",
    "        self.hyperplanes = [generate_hyperplanes(d, k) for _ in range(L)]\n",
    "\n",
    "    def add_vectors(self, vectors, identifiers):\n",
    "        \"\"\"\n",
    "        Add a batch of vectors to the LSH index.\n",
    "\n",
    "        Parameters:\n",
    "        - vectors: Input vectors (2D array of shape [n_samples, d]).\n",
    "        - identifiers: A list of unique identifiers for the vectors.\n",
    "        \"\"\"\n",
    "        for table, hyperplanes in zip(self.tables, self.hyperplanes):\n",
    "            # Compute hash values for all vectors at once\n",
    "            hash_values = hash_vectors(vectors, hyperplanes)\n",
    "            \n",
    "            # Convert binary hash values to tuples for dictionary keys\n",
    "            hash_keys = [tuple(h) for h in hash_values]\n",
    "            \n",
    "            # Add vectors to their corresponding buckets\n",
    "            for identifier, key in zip(identifiers, hash_keys):\n",
    "                table[key].append(identifier)\n",
    "\n",
    "    def query(self, vectors):\n",
    "        \"\"\"\n",
    "        Query the LSH index to find similar items for a batch of vectors.\n",
    "\n",
    "        Parameters:\n",
    "        - vectors: Query vectors (2D array of shape [n_samples, d]).\n",
    "\n",
    "        Returns:\n",
    "        - A list of sets, where each set contains the candidates for a query vector.\n",
    "        \"\"\"\n",
    "        candidates = [set() for _ in range(len(vectors))]\n",
    "        for table, hyperplanes in zip(self.tables, self.hyperplanes):\n",
    "            # Compute hash values for all query vectors\n",
    "            hash_values = hash_vectors(vectors, hyperplanes)\n",
    "            \n",
    "            # Convert binary hash values to tuples for dictionary keys\n",
    "            hash_keys = [tuple(h) for h in hash_values]\n",
    "            \n",
    "            # Retrieve candidates for each query\n",
    "            for i, key in enumerate(hash_keys):\n",
    "                candidates[i].update(table.get(key, []))\n",
    "        return candidates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Run LSH ##\n",
    "# Initialize LSH scheme\n",
    "d = 384\n",
    "k = 14 \n",
    "L = 7\n",
    "\n",
    "lsh = LSHVectorized(d, k, L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add vectors to the LSH index\n",
    "lsh.add_vectors(vectors[1:], identifiers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4104"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test query\n",
    "test_vector = vectors[0].reshape(1, -1)  # Use the first vector as an example query\n",
    "candidates = lsh.query(test_vector)\n",
    "len(candidates[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1109"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(df_filtered[df_filtered[\"id\"].isin(list(candidates[0]))][\"name\"])) # Different beer in bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_vectors = df_filtered[df_filtered[\"id\"].isin(list(candidates[0]))][\"sbert_embedding\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = df_filtered[df_filtered[\"id\"].isin(list(candidates[0]))].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_vectors = np.vstack(bucket_vectors.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the similarity in bucket:\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "sims = cosine_similarity(test_vector, bucket_vectors)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "beer_similarities = pd.DataFrame({\n",
    "    'similarity': sims,\n",
    "    'beer': df_filtered[df_filtered[\"id\"].isin(list(candidates[0]))][\"name\"].values  # Ensure this corresponds to your bucket_vectors\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>similarity</th>\n",
       "      <th>beer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.322743</td>\n",
       "      <td>Oitava Colina Vila Berta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.387336</td>\n",
       "      <td>Dois Corvos / Frontaal Guanabana Mañana Smooth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.240947</td>\n",
       "      <td>Dois Corvos Creature</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.447152</td>\n",
       "      <td>Dois Corvos Creature</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.344319</td>\n",
       "      <td>Dois Corvos Matiné Session IPA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012</th>\n",
       "      <td>0.214279</td>\n",
       "      <td>Leroy Stout</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013</th>\n",
       "      <td>0.303932</td>\n",
       "      <td>Gruut Amber Ale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014</th>\n",
       "      <td>0.501188</td>\n",
       "      <td>Mongozo Palmnut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015</th>\n",
       "      <td>0.496383</td>\n",
       "      <td>Seefbier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016</th>\n",
       "      <td>0.504536</td>\n",
       "      <td>Seefbier</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2017 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      similarity                                               beer\n",
       "0       0.322743                           Oitava Colina Vila Berta\n",
       "1       0.387336  Dois Corvos / Frontaal Guanabana Mañana Smooth...\n",
       "2       0.240947                               Dois Corvos Creature\n",
       "3       0.447152                               Dois Corvos Creature\n",
       "4       0.344319                     Dois Corvos Matiné Session IPA\n",
       "...          ...                                                ...\n",
       "2012    0.214279                                        Leroy Stout\n",
       "2013    0.303932                                    Gruut Amber Ale\n",
       "2014    0.501188                                    Mongozo Palmnut\n",
       "2015    0.496383                                           Seefbier\n",
       "2016    0.504536                                           Seefbier\n",
       "\n",
       "[2017 rows x 2 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beer_similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_similarities_per_beer = beer_similarities.groupby('beer')['similarity'].mean()\n",
    "# TODO Kommenter på at mean kan ødelægge modsættende reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.32274258, 0.38733554, 0.24094652, ..., 0.48198116, 0.4326756 ,\n",
       "       0.32503977], dtype=float32)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sims[:-20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                                                                  1\n",
       "name                                                Wild Dog Pale Ale\n",
       "brewery                                       Wild Dog (Tiemann Beer)\n",
       "subgenre                                            American Pale Ale\n",
       "abv                                                               5.2\n",
       "location                                                     🇯🇪Jersey\n",
       "rating                                                            3.5\n",
       "average_rating                                                   2.99\n",
       "reviewer                                             Jerseyislandbeer\n",
       "review_date                                         December 14, 2023\n",
       "review_text         330ml can from Shoprite in Livingstone. At hom...\n",
       "algorithm_rating                                                 28.0\n",
       "total_reviews                                                      11\n",
       "sbert_embedding     [0.037878353, 0.00593541, 0.0062317043, -0.011...\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filtered.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "beer\n",
       "Protokoll Billie is a Punk Rocker                           0.649359\n",
       "CRAK Mundaka Session IPA                                    0.632073\n",
       "Hoppin' Frog Frogichlaus                                    0.619754\n",
       "Lough Gill Spear                                            0.617472\n",
       "De Dochter van de Korenaar L'Ensemble Double Barrel-Aged    0.614338\n",
       "Name: similarity, dtype: float32"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_similarities_per_beer.nlargest(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make CF\n",
    "def collaborative_filtering(df, user_id,  k,  drop_cols = [\"brewery\", \"subgenre\", \"abv\", \"sbert_embedding\"]):\n",
    "    df_colab = df.drop(drop_cols, axis=1)\n",
    "\n",
    "    # TODO Tænk over om normalisering giver mening ift. at man måske bare godt kan lide alle øl?\n",
    "    # For man har ikke alle personens anmeldelser kun dens anmeldelser af gode øl\n",
    "    # Alternativt \"normaliser\" ved at ændre skal ved threshold, så dårlig rating bliver negativ (hvis man bruger cosine)\n",
    "    # Evt. normalise mellem 0 og 5\n",
    "    threshold = 3 # Threshold for like/hate\n",
    "    # TODO Maybe when inserting threshold determine it based on the average rating of a user?\n",
    "    df_colab[\"like/hate\"] = df_colab[\"rating\"].apply(lambda x: 1 if x >= threshold else 0)\n",
    "    utility_matrix = df_colab.pivot_table(index='reviewer', columns='name', values='like/hate')\n",
    "    # fill missing values with NaN or 0 (change depending on  approach)\n",
    "    utility_matrix = utility_matrix.fillna(0)\n",
    "    binary_matrix = utility_matrix.values\n",
    "    user = binary_matrix[user_id,:]\n",
    "    # Compute intersections\n",
    "    intersection = np.dot(user, binary_matrix.T)\n",
    "\n",
    "    # Compute union\n",
    "    union = np.bitwise_or(user.reshape(1, -1).astype(int), binary_matrix.astype(int)).sum(axis=1)\n",
    "\n",
    "    # Compute Jaccard similarity\n",
    "    jaccard_similarity = intersection / union\n",
    "    similarity_df = pd.DataFrame(jaccard_similarity, index=utility_matrix.index, columns=['Jaccard Similarity'])\n",
    "\n",
    "    # Compute cosine\n",
    "    norm_product = np.linalg.norm(user) * np.linalg.norm(binary_matrix, axis=1)\n",
    "    cosine_similarity = intersection / norm_product\n",
    "    similarity_df[\"Cosine\"] = cosine_similarity\n",
    "\n",
    "    # Get the top-k similar users for each user\n",
    "    # TODO filter away all similarities below a certain threshold\n",
    "    # K Number of neighbors\n",
    "    top_k_neighbors_jaccard = similarity_df.nlargest(k, \"Jaccard Similarity\")\n",
    "    top_k_neighbors_cosine = similarity_df.nlargest(k, \"Cosine Similarity\")\n",
    "    return top_k_neighbors_jaccard, top_k_neighbors_cosine # Top k users with most similar taste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def predict_ratings_user_based(user_item_matrix, similarity_matrix):\n",
    "    # TODO Hvordan håndterer vi øl personen allerede har rated\n",
    "    # Convert to a numpy array for computation\n",
    "    user_item_matrix = user_item_matrix.values\n",
    "\n",
    "    # Compute mean ratings for each user\n",
    "    user_means = np.ma.masked_equal(user_item_matrix, 0).mean(axis=1).filled(0)\n",
    "    \n",
    "    # Center the matrix by subtracting user means\n",
    "    ratings_diff = user_item_matrix - user_means[:, None]\n",
    "    ratings_diff[np.isnan(ratings_diff)] = 0  # Replace NaN deviations with 0\n",
    "\n",
    "    # Compute predictions\n",
    "    similarity_sum = np.abs(similarity_matrix).sum(axis=1)[:, None]\n",
    "    pred = user_means[:, None] + np.dot(similarity_matrix, ratings_diff) / (similarity_sum + 1e-8)\n",
    "    \n",
    "    return pred\n",
    "\n",
    "\n",
    "def collaborative_filtering(df, drop_cols = [\"brewery\", \"subgenre\", \"abv\", \"sbert_embedding\"]):\n",
    "    #df_colab = df.drop(drop_cols, axis=1)\n",
    "    df_colab = df\n",
    "    #df_colab['rating'] = pd.to_numeric(df_colab['rating'], errors='coerce')  # Coerce invalid parsing to NaN\n",
    "    #df_colab = df_colab.dropna(subset=['rating'])  # Drop rows where 'rating' is NaN\n",
    "\n",
    "\n",
    "    user_item_matrix = df_colab.pivot_table(\n",
    "        index=\"reviewer\",     # Rows: Reviewers\n",
    "        columns=\"name\",       # Columns: Beer names\n",
    "        values=\"rating\",      # Values: Ratings\n",
    "        fill_value=0          # Fill missing ratings with 0\n",
    "    )\n",
    "    \n",
    "\n",
    "    # Compute cosine similarity\n",
    "    #cosine_similarity = compute_cosine_similarity_manual(utility_matrix.values)\n",
    "    cosine_similarity_matrix = cosine_similarity(user_item_matrix)\n",
    "    \n",
    "    # Predict ratings\n",
    "    predicted_ratings = predict_ratings_user_based(user_item_matrix, cosine_similarity_matrix)\n",
    "\n",
    "    pr_df = pd.DataFrame(predicted_ratings, index=user_item_matrix.index, columns=user_item_matrix.columns)\n",
    "\n",
    "\n",
    "    return pr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr_df = collaborative_filtering(df_filtered).loc[\"Jerseyislandbeer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                                                                  1\n",
       "name                                                Wild Dog Pale Ale\n",
       "brewery                                       Wild Dog (Tiemann Beer)\n",
       "subgenre                                            American Pale Ale\n",
       "abv                                                               5.2\n",
       "location                                                     🇯🇪Jersey\n",
       "rating                                                            3.5\n",
       "average_rating                                                   2.99\n",
       "reviewer                                             Jerseyislandbeer\n",
       "review_date                                         December 14, 2023\n",
       "review_text         330ml can from Shoprite in Livingstone. At hom...\n",
       "algorithm_rating                                                 28.0\n",
       "total_reviews                                                      11\n",
       "sbert_embedding     [0.037878353, 0.00593541, 0.0062317043, -0.011...\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filtered.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name\n",
       "Trappistes Rochefort 10                 1.272651\n",
       "Chimay Grande Réserve (Bleue / Blue)    1.253129\n",
       "St. Bernardus Abt 12                    1.171847\n",
       "Orval                                   1.135382\n",
       "Duvel                                   1.068443\n",
       "Name: Jerseyislandbeer, dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pr_df.loc[\"Jerseyislandbeer\"].nlargest(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make reccomendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_scores = pr_df[average_similarities_per_beer.index.tolist()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "beer\n",
       "Protokoll Billie is a Punk Rocker                           0.649359\n",
       "CRAK Mundaka Session IPA                                    0.632073\n",
       "Hoppin' Frog Frogichlaus                                    0.619754\n",
       "Lough Gill Spear                                            0.617472\n",
       "De Dochter van de Korenaar L'Ensemble Double Barrel-Aged    0.614338\n",
       "Camba Bavaria Pale Ale                                      0.611723\n",
       "Hill Farmstead Aaron                                        0.604761\n",
       "Hop Hooligans Royal Execution                               0.602853\n",
       "Galway Bay / Pühaste Tharapita                              0.601325\n",
       "Aecht Schlenkerla Weichsel Rotbier                          0.599909\n",
       "Name: similarity, dtype: float32"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_similarities_per_beer.nlargest(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name\n",
       "Trappistes Rochefort 10                1.272651\n",
       "St. Bernardus Abt 12                   1.171847\n",
       "Ayinger Celebrator Doppelbock          1.003624\n",
       "Schneider Weisse Tap 06 - Aventinus    0.962352\n",
       "Westmalle Dubbel                       0.808483\n",
       "Hoegaarden                             0.793364\n",
       "Weihenstephaner Hefeweissbier          0.762673\n",
       "Westvleteren 12                        0.727192\n",
       "Founders Breakfast Stout               0.703024\n",
       "AleSmith Speedway Stout                0.675715\n",
       "Name: Jerseyislandbeer, dtype: float64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cf_scores.loc[\"Jerseyislandbeer\"].nlargest(10)\n",
    "# TODO normalization works? values larger tahn 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "totoal_score = 1* cf_scores.loc[\"Jerseyislandbeer\"] + 1* average_similarities_per_beer\n",
    "# TODO Tilføj alpha og gang med hhv. a og (1-a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name\n",
       "Trappistes Rochefort 10                        1.684413\n",
       "St. Bernardus Abt 12                           1.575763\n",
       "Ayinger Celebrator Doppelbock                  1.366831\n",
       "Schneider Weisse Tap 06 - Aventinus            1.344995\n",
       "Westmalle Dubbel                               1.238715\n",
       "Hoegaarden                                     1.144097\n",
       "Westvleteren 12                                1.138287\n",
       "Weihenstephaner Hefeweissbier                  1.116987\n",
       "Bell's Expedition Stout                        1.089095\n",
       "Paulaner Salvator                              1.081327\n",
       "Rodenbach Grand Cru                            1.059474\n",
       "Unibroue Trois Pistoles                        1.046831\n",
       "Saison Dupont                                  1.043657\n",
       "Schneider Weisse Tap 09 - Aventinus Eisbock    1.033184\n",
       "AleSmith Speedway Stout                        1.025854\n",
       "Founders Breakfast Stout                       1.009977\n",
       "Founders KBS (Kentucky Breakfast Stout)        1.000817\n",
       "Stone Imperial Russian Stout                   0.971501\n",
       "Chouffe Houblon IPA / Dobbelen IPA Tripel      0.952739\n",
       "Goose Island Bourbon County Stout              0.935175\n",
       "dtype: float64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "totoal_score.nlargest(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "beer_info = df_filtered[['name', 'abv', 'subgenre']]\n",
    "\n",
    "# Drop duplicate rows based on the 'name' column\n",
    "beer_info = beer_info.drop_duplicates(subset='name')\n",
    "\n",
    "# Set the 'name' column as the index\n",
    "beer_info.set_index('name', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Penalise difference in abv\n",
    "abv = beer_info.loc[average_similarities_per_beer.index.tolist()][\"abv\"]\n",
    "abv_2 = 5.2\n",
    "alpha = 0.03\n",
    "if abv_2 == 0:\n",
    "    total_score_plus = totoal_score - 2 * abs(abv - abv_2) # Ensure zero percent alchol\n",
    "else:\n",
    "    total_score_plus = totoal_score - alpha * ((abv - abv_2)**2) / (abv_2**1.5 + 1)\n",
    "# TODO how to penalise abv: linearly, logarithmic, squared?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "squared:  0.18\n",
      "linear 0.06\n",
      "logarithmic:  0.027725887222397813\n",
      "logarithmic scaled:  0.008109302162163289\n",
      "linear scaled:  0.01\n",
      "Squared scaled:  0.011467204289329453\n"
     ]
    }
   ],
   "source": [
    "# Test abv scaling\n",
    "alpha = 0.02\n",
    "abv_1 = 9\n",
    "abv_2 = 6\n",
    "\n",
    "print(\"squared: \", alpha * (abv_1 - abv_2)**2)\n",
    "print(\"linear\", alpha*(abv_1 - abv_2))\n",
    "print(\"logarithmic: \", alpha * np.log(1 + abs(abv_1 - abv_2)))\n",
    "print(\"logarithmic scaled: \", alpha * np.log(1 + abs(abv_1 - abv_2) / abv_2))\n",
    "print(\"linear scaled: \", alpha * abs(abv_1 - abv_2) / abv_2)\n",
    "print(\"Squared scaled: \", alpha * (abs(abv_1 - abv_2)**2) / (abv_2**1.5 + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add bonus for match in style\n",
    "relevant_styles = beer_info.loc[average_similarities_per_beer.index.tolist()][\"subgenre\"]\n",
    "style = \"American Pale Ale\"\n",
    "style_mask = relevant_styles == style\n",
    "style_bonus = np.zeros(len(totoal_score))\n",
    "style_bonus[style_mask] = 0.1 \n",
    "\n",
    "total_score_plus += style_bonus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name\n",
       "Trappistes Rochefort 10                1.597595\n",
       "St. Bernardus Abt 12                   1.522006\n",
       "Ayinger Celebrator Doppelbock          1.361581\n",
       "Schneider Weisse Tap 06 - Aventinus    1.323996\n",
       "Westmalle Dubbel                       1.231155\n",
       "Hoegaarden                             1.143887\n",
       "Weihenstephaner Hefeweissbier          1.116893\n",
       "Westvleteren 12                        1.079957\n",
       "Paulaner Salvator                      1.064318\n",
       "Rodenbach Grand Cru                    1.057981\n",
       "dtype: float64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_score_plus.nlargest(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Abbey Dubbel',\n",
       " 'Abbey Tripel',\n",
       " 'Abt/Quadrupel',\n",
       " 'All Cider Styles',\n",
       " 'All Sake Styles',\n",
       " 'Altbier',\n",
       " 'Amber Ale',\n",
       " 'Amber Lager/Vienna',\n",
       " 'American Pale Ale',\n",
       " 'American Strong Ale',\n",
       " 'Anglo-American Ales',\n",
       " 'Baltic Porter',\n",
       " 'Barley Wine',\n",
       " 'Belgian Ale',\n",
       " 'Belgian Strong Ale',\n",
       " 'Belgian-Style Ales',\n",
       " 'Berliner Weisse',\n",
       " 'Bitter',\n",
       " 'Bière de Garde',\n",
       " 'Black IPA',\n",
       " 'Brown Ale',\n",
       " 'California Common',\n",
       " 'Cider',\n",
       " 'Cream Ale',\n",
       " 'Czech Pilsner (Svetlý)',\n",
       " 'Doppelbock',\n",
       " 'Dortmunder/Helles',\n",
       " 'Dry Stout',\n",
       " 'Dunkel/Tmavý',\n",
       " 'Dunkelweizen',\n",
       " 'Dunkler Bock',\n",
       " 'Eisbock',\n",
       " 'English Pale Ale',\n",
       " 'English Strong Ale',\n",
       " 'Foreign Stout',\n",
       " 'Fruit Beer',\n",
       " 'German Hefeweizen',\n",
       " 'German Kristallweizen',\n",
       " 'Golden Ale/Blond Ale',\n",
       " 'Grodziskie/Gose/Lichtenhainer',\n",
       " 'Heller Bock',\n",
       " 'Ice Cider/Perry',\n",
       " 'Imperial Pils/Strong Pale Lager',\n",
       " 'Imperial Stout',\n",
       " 'Imperial/Double IPA',\n",
       " 'Imperial/Strong Porter',\n",
       " 'India Pale Ale (IPA)',\n",
       " 'Irish Ale',\n",
       " 'Kölsch',\n",
       " 'Lagers',\n",
       " 'Lambic and Sour Ale',\n",
       " 'Low Alcohol',\n",
       " 'Malt Liquor',\n",
       " 'Mead',\n",
       " 'Mild Ale',\n",
       " 'Oktoberfest/Märzen',\n",
       " 'Old Ale',\n",
       " 'Pale Lager',\n",
       " 'Perry',\n",
       " 'Pilsener',\n",
       " 'Polotmavý',\n",
       " 'Porter',\n",
       " 'Premium Bitter/ESB',\n",
       " 'Premium Lager',\n",
       " 'Sahti/Gotlandsdricke/Koduõlu',\n",
       " 'Saison',\n",
       " 'Schwarzbier',\n",
       " 'Scotch Ale',\n",
       " 'Scottish Ale',\n",
       " 'Session IPA',\n",
       " 'Smoked',\n",
       " 'Sour Red/Brown',\n",
       " 'Sour/Wild Ale',\n",
       " 'Specialty Grain',\n",
       " 'Spice/Herb/Vegetable',\n",
       " 'Stout',\n",
       " 'Stouts and Porters',\n",
       " 'Sweet Stout',\n",
       " 'Traditional Ale',\n",
       " 'Traditional, Spice, Other',\n",
       " 'Weizenbock',\n",
       " 'Wheat Ale',\n",
       " 'Wheat Beer',\n",
       " 'Witbier',\n",
       " 'Zwickel/Keller/Landbier'}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO Tilføj overkategorier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate\n",
    "# Evaluer tid det tager\n",
    "# Evalear precision og recall på reccomendations\n",
    "# Evaluer og tune paramteres LSH\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
